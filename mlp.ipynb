{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read data\n",
    "df = pd.read_csv('data-sets/air_passengers.csv')\n",
    "\n",
    "# Create lagged features\n",
    "for i in range(1, 3):\n",
    "    df[f'lag_{i}'] = df['Passengers'].shift(i)\n",
    "\n",
    "# Drop NA values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Define inputs and target\n",
    "X = df[['lag_1', 'lag_2']].values\n",
    "y = df['Passengers'].values\n",
    "\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)  # 0.2 x 0.8 = 0.16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "class FeedForwardNetwork(pl.LightningModule):\n",
    "    def __init__(self, hidden_size, input_size=2, output_size=1):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        return self.layer2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization, UtilityFunction\n",
    "from sympy import Integer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "class LightningModel(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate, weight_decay):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        y_hat = y_hat.view(-1)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        y_hat = y_hat.view(-1)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        self.log('test_loss', loss)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
    "\n",
    "# Preparing data loaders outside the train_model function\n",
    "train_dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train))\n",
    "val_dataset = TensorDataset(torch.Tensor(X_val), torch.Tensor(y_val))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# Define a function for training a model, which we will optimize\n",
    "def train_model(log_learning_rate: float, weight_decay: float, hidden_size: float):\n",
    "   \n",
    "    # Rounding and converting to integer because BayesianOptimization gives us float values\n",
    "    hidden_size = int(round(hidden_size))\n",
    "\n",
    "    # Transform the learning rate from log space to its original space\n",
    "    learning_rate = 10 ** log_learning_rate\n",
    "\n",
    "    model = FeedForwardNetwork(hidden_size=hidden_size)\n",
    "    lightning_model = LightningModel(model, learning_rate, weight_decay)\n",
    "    \n",
    "    logger = TensorBoardLogger('tb_logs', name='my_model')\n",
    "\n",
    "\n",
    "    trainer = pl.Trainer(max_epochs=100, logger=logger)\n",
    "    trainer.fit(lightning_model, train_loader, val_loader)\n",
    "    \n",
    "    # Return the validation loss for the last epoch\n",
    "    return -trainer.callback_metrics['train_loss'].item()\n",
    "\n",
    "# Defining our BayesianOptimization object\n",
    "optimizer = BayesianOptimization(\n",
    "    f = train_model,\n",
    "    pbounds = {\n",
    "        \"log_learning_rate\": (-5, -1), \n",
    "        \"weight_decay\": (1e-5, 0.1), \n",
    "        \"hidden_size\": (32, 128),\n",
    "    \n",
    "    },\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Define a UtilityFunction object, which determines how the next point to probe is picked.\n",
    "utility = UtilityFunction(kind=\"ucb\", kappa=2.5, xi=0.0)\n",
    "\n",
    "# Perform Bayesian optimization for 5 iterations\n",
    "for _ in range(5):\n",
    "    next_point_to_probe = optimizer.suggest(utility)\n",
    "    target = train_model(**next_point_to_probe)\n",
    "    optimizer.register(params=next_point_to_probe, target=target)\n",
    "\n",
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve best parameters\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "best_params = optimizer.max['params']\n",
    "\n",
    "# Re-calculate the learning rate from its logarithm\n",
    "best_params['log_learning_rate'] = 10 ** best_params['log_learning_rate']\n",
    "\n",
    "# Ensure hidden_size is an integer\n",
    "best_params['hidden_size'] = int(round(best_params['hidden_size']))\n",
    "\n",
    "# Train a new model with the best parameters\n",
    "model = FeedForwardNetwork(input_size=2, hidden_size=best_params['hidden_size'])\n",
    "lightning_model = LightningModel(model, best_params['log_learning_rate'], best_params['weight_decay'])\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=1000)\n",
    "trainer.fit(lightning_model, train_loader, val_loader)\n",
    "\n",
    "# Predicting\n",
    "lightning_model.eval()\n",
    "predictions = lightning_model(torch.Tensor(X_test))\n",
    "\n",
    "# Plotting\n",
    "plt.plot(y_test, label='Actual')\n",
    "plt.plot(predictions.detach().numpy(), label='Predicted')\n",
    "plt.legend()\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Passengers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "mape = mean_absolute_percentage_error(predictions.detach().numpy(), y_test)\n",
    "print(\"Mape:\", mape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
