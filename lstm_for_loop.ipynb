{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Read data\n",
    "df = pd.read_csv('data-sets/air_passengers.csv')\n",
    "\n",
    "# Create lagged features\n",
    "for i in range(1, 3):\n",
    "    df[f'lag_{i}'] = df['Passengers'].shift(i)\n",
    "\n",
    "# Drop NA values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Define inputs and target\n",
    "X = df[['lag_1', 'lag_2']].values\n",
    "y = df['Passengers'].values\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)  # 0.2 x 0.8 = 0.16\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train = y_scaler.fit_transform(y_train.reshape(-1, 1))\n",
    "y_val = y_scaler.transform(y_val.reshape(-1, 1))\n",
    "y_test = y_scaler.transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "import torch\n",
    "from torch import nn\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "class LSTM(pl.LightningModule):\n",
    "    def __init__(self, input_size, hidden_layer_size, num_layers, lr, weight_decay, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.loss_func = nn.MSELoss()\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, _ = self.lstm(input_seq.view(len(input_seq), -1))\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.loss_func(y_hat, y)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameters for grid search\n",
    "learning_rates = [0.01, 0.1]\n",
    "epochs = [1, 2]\n",
    "hidden_sizes = [50, 100]\n",
    "layers = [1, 2, 3]\n",
    "weight_decays = [1e-3, 1e-2]\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# Preparing data loaders\n",
    "train_dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train))\n",
    "val_dataset = TensorDataset(torch.Tensor(X_val), torch.Tensor(y_val))\n",
    "test_dataset = TensorDataset(torch.Tensor(X_test), torch.Tensor(y_test))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Initialize minimum loss and best model\n",
    "min_loss = float('inf')\n",
    "best_model = None\n",
    "best_params = None\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_val_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Define the logger\n",
    "logger = TensorBoardLogger('tb_logs', name='my_model')\n",
    "\n",
    "print(X_val)\n",
    "# Iterate over hyperparameters\n",
    "for lr in learning_rates:\n",
    "    for epoch in epochs:\n",
    "        for hidden_size in hidden_sizes:\n",
    "            for layer in layers:\n",
    "                for weight_decay in weight_decays:\n",
    "                    model = LSTM(input_size=2, hidden_layer_size=hidden_size, num_layers=layer, lr=lr, weight_decay=weight_decay)\n",
    "                    trainer = Trainer(max_epochs=epoch, logger=logger)\n",
    "                    trainer.fit(model, train_loader, val_loader)\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        predictions = model(X_val_tensor)\n",
    "                        #loss = model.loss_func(predictions, y_val_tensor)\n",
    "                        #predictions = y_scaler.inverse_transform(predictions)\n",
    "                        loss = model.loss_func(predictions, y_val_tensor)\n",
    "                        if loss.item() < min_loss:\n",
    "                            min_loss = loss.item()\n",
    "                            best_model = model\n",
    "                            best_params = {'lr': lr, 'epoch': epoch, 'hidden_size': hidden_size, 'layer': layer, 'weight_decay': weight_decay}\n",
    "\n",
    "print(\"Best model parameters:\", best_params)\n",
    "print(\"Best model minimum loss:\", min_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model.eval()\n",
    "\n",
    "# # Prepare your test data as tensor\n",
    "# X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "# y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# # Move your test data to the same device as your model\n",
    "# #device = torch.device('cpu')\n",
    "# #\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     predictions = best_model(X_test_tensor)\n",
    "#     # Inverse transform predictions if your target variable was scaled\n",
    "#     predictions = y_scaler.inverse_transform(predictions)\n",
    "#     test_loss = best_model.loss_func(predictions, y_test)\n",
    "\n",
    "# print(\"Test Loss: \", test_loss.item())\n",
    "\n",
    "# **********\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predicting\n",
    "best_model.eval()\n",
    "predictions = best_model(torch.Tensor(X_test))\n",
    "print(predictions)\n",
    "\n",
    "# Plotting\n",
    "plt.plot(y_test, label='Actual')\n",
    "plt.plot(predictions.detach().numpy(), label='Predicted')\n",
    "plt.legend()\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Passengers')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
