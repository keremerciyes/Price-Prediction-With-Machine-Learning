{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\cemer\\OneDrive\\Belgeler\\GitHub\\price-prediction-with-machine-learning\\lstm_cv_test.ipynb Cell 1\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cemer/OneDrive/Belgeler/GitHub/price-prediction-with-machine-learning/lstm_cv_test.ipynb#W0sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m X_train, X_val \u001b[39m=\u001b[39m X_train_val[train_indices], X_train_val[val_indices]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/cemer/OneDrive/Belgeler/GitHub/price-prediction-with-machine-learning/lstm_cv_test.ipynb#W0sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m y_train, y_val \u001b[39m=\u001b[39m y_train_val[train_indices], y_train_val[val_indices]\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/cemer/OneDrive/Belgeler/GitHub/price-prediction-with-machine-learning/lstm_cv_test.ipynb#W0sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m train_losses, val_losses \u001b[39m=\u001b[39m train_and_validate(X_train, y_train, X_val, y_val, num_epochs, device)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/cemer/OneDrive/Belgeler/GitHub/price-prediction-with-machine-learning/lstm_cv_test.ipynb#W0sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m train_losses_all\u001b[39m.\u001b[39mappend(train_losses)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/cemer/OneDrive/Belgeler/GitHub/price-prediction-with-machine-learning/lstm_cv_test.ipynb#W0sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m val_losses_all\u001b[39m.\u001b[39mappend(val_losses)\n",
      "\u001b[1;32mc:\\Users\\cemer\\OneDrive\\Belgeler\\GitHub\\price-prediction-with-machine-learning\\lstm_cv_test.ipynb Cell 1\u001b[0m in \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cemer/OneDrive/Belgeler/GitHub/price-prediction-with-machine-learning/lstm_cv_test.ipynb#W0sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m X_val_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(X_val, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cemer/OneDrive/Belgeler/GitHub/price-prediction-with-machine-learning/lstm_cv_test.ipynb#W0sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m y_val_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(y_val, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/cemer/OneDrive/Belgeler/GitHub/price-prediction-with-machine-learning/lstm_cv_test.ipynb#W0sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m model \u001b[39m=\u001b[39m TimeSeriesLSTM(input_size, hidden_size, num_layers, output_size, dropout_prob\u001b[39m=\u001b[39mdropout_prob)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cemer/OneDrive/Belgeler/GitHub/price-prediction-with-machine-learning/lstm_cv_test.ipynb#W0sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/cemer/OneDrive/Belgeler/GitHub/price-prediction-with-machine-learning/lstm_cv_test.ipynb#W0sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlearning_rate, weight_decay\u001b[39m=\u001b[39mweight_decay)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_size' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "\n",
    "# Generate sinusoidal time series data\n",
    "def generate_sin_wave(freq, num_samples, sample_rate):\n",
    "    x = np.linspace(0, num_samples / sample_rate, num_samples)\n",
    "    y = np.sin(2 * np.pi * freq * x)\n",
    "    return y\n",
    "\n",
    "# Create input-target pairs for the LSTM model\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length - 1):\n",
    "        seq = data[i : (i + seq_length)]\n",
    "        X.append(seq)\n",
    "        target = data[i + seq_length]\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Define the LSTM model with dropout\n",
    "class TimeSeriesLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_prob):\n",
    "        super(TimeSeriesLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Generate sinusoidal time series data\n",
    "freq = 2\n",
    "num_samples = 200\n",
    "sample_rate = 10\n",
    "data = generate_sin_wave(freq, num_samples, sample_rate)\n",
    "\n",
    "# Prepare the data for the LSTM model\n",
    "seq_length = 20\n",
    "X, y = create_sequences(data, seq_length)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "y = y.reshape(y.shape[0], 1)\n",
    "\n",
    "# Split the dataset into training, validation, and testing sets (80% train, 20% test)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to train and validate the model\n",
    "def train_and_validate(X_train, y_train, X_val, y_val, num_epochs, device):\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
    "\n",
    "    model = TimeSeriesLSTM(input_size, hidden_size, num_layers, output_size, dropout_prob=dropout_prob).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val_tensor)\n",
    "            val_loss = criterion(val_outputs, y_val_tensor)\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "num_epochs = 100\n",
    "k_folds = 5\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "train_losses_all = []\n",
    "val_losses_all = []\n",
    "\n",
    "for fold, (train_indices, val_indices) in enumerate(kfold.split(X_train_val, y_train_val)):\n",
    "    X_train, X_val = X_train_val[train_indices], X_train_val[val_indices]\n",
    "    y_train, y_val = y_train_val[train_indices], y_train_val[val_indices]\n",
    "\n",
    "    train_losses, val_losses = train_and_validate(X_train, y_train, X_val, y_val, num_epochs, device)\n",
    "    train_losses_all.append(train_losses)\n",
    "    val_losses_all.append(val_losses)\n",
    "\n",
    "    print(f\"Fold {fold + 1}: Final Training Loss: {train_losses[-1]:.4f}, Final Validation Loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "# Train the final model on the combined training and validation sets\n",
    "train_losses, _ = train_and_validate(X_train_val, y_train_val, X_val, y_val, num_epochs, device)\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "model.eval()\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "y_pred = model(X_test_tensor).detach().cpu().numpy()\n",
    "\n",
    "# Plot the generated sine wave, ground truth, and predicted sine wave\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data, label=\"Generated Sine Wave\")\n",
    "plt.plot(range(len(X_train_val) + seq_length, len(data) - 1), y_test, label=\"Ground Truth\")\n",
    "plt.plot(range(len(X_train_val) + seq_length, len(data) - 1), y_pred, label=\"Predicted Sine Wave\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation losses\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(k_folds):\n",
    "    plt.plot(range(1, num_epochs + 1), train_losses_all[i], label=f\"Training Loss (Fold {i + 1})\")\n",
    "    plt.plot(range(1, num_epochs + 1), val_losses_all[i], label=f\"Validation Loss (Fold {i + 1})\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
