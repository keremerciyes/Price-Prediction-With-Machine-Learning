{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=Passengers<br>Month=%{x}<br>Passengers=%{y}<extra></extra>",
         "legendgroup": "Passengers",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Passengers",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "1949-01-01T00:00:00",
          "1949-02-01T00:00:00",
          "1949-03-01T00:00:00",
          "1949-04-01T00:00:00",
          "1949-05-01T00:00:00",
          "1949-06-01T00:00:00",
          "1949-07-01T00:00:00",
          "1949-08-01T00:00:00",
          "1949-09-01T00:00:00",
          "1949-10-01T00:00:00",
          "1949-11-01T00:00:00",
          "1949-12-01T00:00:00",
          "1950-01-01T00:00:00",
          "1950-02-01T00:00:00",
          "1950-03-01T00:00:00",
          "1950-04-01T00:00:00",
          "1950-05-01T00:00:00",
          "1950-06-01T00:00:00",
          "1950-07-01T00:00:00",
          "1950-08-01T00:00:00",
          "1950-09-01T00:00:00",
          "1950-10-01T00:00:00",
          "1950-11-01T00:00:00",
          "1950-12-01T00:00:00",
          "1951-01-01T00:00:00",
          "1951-02-01T00:00:00",
          "1951-03-01T00:00:00",
          "1951-04-01T00:00:00",
          "1951-05-01T00:00:00",
          "1951-06-01T00:00:00",
          "1951-07-01T00:00:00",
          "1951-08-01T00:00:00",
          "1951-09-01T00:00:00",
          "1951-10-01T00:00:00",
          "1951-11-01T00:00:00",
          "1951-12-01T00:00:00",
          "1952-01-01T00:00:00",
          "1952-02-01T00:00:00",
          "1952-03-01T00:00:00",
          "1952-04-01T00:00:00",
          "1952-05-01T00:00:00",
          "1952-06-01T00:00:00",
          "1952-07-01T00:00:00",
          "1952-08-01T00:00:00",
          "1952-09-01T00:00:00",
          "1952-10-01T00:00:00",
          "1952-11-01T00:00:00",
          "1952-12-01T00:00:00",
          "1953-01-01T00:00:00",
          "1953-02-01T00:00:00",
          "1953-03-01T00:00:00",
          "1953-04-01T00:00:00",
          "1953-05-01T00:00:00",
          "1953-06-01T00:00:00",
          "1953-07-01T00:00:00",
          "1953-08-01T00:00:00",
          "1953-09-01T00:00:00",
          "1953-10-01T00:00:00",
          "1953-11-01T00:00:00",
          "1953-12-01T00:00:00",
          "1954-01-01T00:00:00",
          "1954-02-01T00:00:00",
          "1954-03-01T00:00:00",
          "1954-04-01T00:00:00",
          "1954-05-01T00:00:00",
          "1954-06-01T00:00:00",
          "1954-07-01T00:00:00",
          "1954-08-01T00:00:00",
          "1954-09-01T00:00:00",
          "1954-10-01T00:00:00",
          "1954-11-01T00:00:00",
          "1954-12-01T00:00:00",
          "1955-01-01T00:00:00",
          "1955-02-01T00:00:00",
          "1955-03-01T00:00:00",
          "1955-04-01T00:00:00",
          "1955-05-01T00:00:00",
          "1955-06-01T00:00:00",
          "1955-07-01T00:00:00",
          "1955-08-01T00:00:00",
          "1955-09-01T00:00:00",
          "1955-10-01T00:00:00",
          "1955-11-01T00:00:00",
          "1955-12-01T00:00:00",
          "1956-01-01T00:00:00",
          "1956-02-01T00:00:00",
          "1956-03-01T00:00:00",
          "1956-04-01T00:00:00",
          "1956-05-01T00:00:00",
          "1956-06-01T00:00:00",
          "1956-07-01T00:00:00",
          "1956-08-01T00:00:00",
          "1956-09-01T00:00:00",
          "1956-10-01T00:00:00",
          "1956-11-01T00:00:00",
          "1956-12-01T00:00:00",
          "1957-01-01T00:00:00",
          "1957-02-01T00:00:00",
          "1957-03-01T00:00:00",
          "1957-04-01T00:00:00",
          "1957-05-01T00:00:00",
          "1957-06-01T00:00:00",
          "1957-07-01T00:00:00",
          "1957-08-01T00:00:00",
          "1957-09-01T00:00:00",
          "1957-10-01T00:00:00",
          "1957-11-01T00:00:00",
          "1957-12-01T00:00:00",
          "1958-01-01T00:00:00",
          "1958-02-01T00:00:00",
          "1958-03-01T00:00:00",
          "1958-04-01T00:00:00",
          "1958-05-01T00:00:00",
          "1958-06-01T00:00:00",
          "1958-07-01T00:00:00",
          "1958-08-01T00:00:00",
          "1958-09-01T00:00:00",
          "1958-10-01T00:00:00",
          "1958-11-01T00:00:00",
          "1958-12-01T00:00:00",
          "1959-01-01T00:00:00",
          "1959-02-01T00:00:00",
          "1959-03-01T00:00:00",
          "1959-04-01T00:00:00",
          "1959-05-01T00:00:00",
          "1959-06-01T00:00:00",
          "1959-07-01T00:00:00",
          "1959-08-01T00:00:00",
          "1959-09-01T00:00:00",
          "1959-10-01T00:00:00",
          "1959-11-01T00:00:00",
          "1959-12-01T00:00:00",
          "1960-01-01T00:00:00",
          "1960-02-01T00:00:00",
          "1960-03-01T00:00:00",
          "1960-04-01T00:00:00",
          "1960-05-01T00:00:00",
          "1960-06-01T00:00:00",
          "1960-07-01T00:00:00",
          "1960-08-01T00:00:00",
          "1960-09-01T00:00:00",
          "1960-10-01T00:00:00",
          "1960-11-01T00:00:00",
          "1960-12-01T00:00:00"
         ],
         "xaxis": "x",
         "y": [
          112,
          118,
          132,
          129,
          121,
          135,
          148,
          148,
          136,
          119,
          104,
          118,
          115,
          126,
          141,
          135,
          125,
          149,
          170,
          170,
          158,
          133,
          114,
          140,
          145,
          150,
          178,
          163,
          172,
          178,
          199,
          199,
          184,
          162,
          146,
          166,
          171,
          180,
          193,
          181,
          183,
          218,
          230,
          242,
          209,
          191,
          172,
          194,
          196,
          196,
          236,
          235,
          229,
          243,
          264,
          272,
          237,
          211,
          180,
          201,
          204,
          188,
          235,
          227,
          234,
          264,
          302,
          293,
          259,
          229,
          203,
          229,
          242,
          233,
          267,
          269,
          270,
          315,
          364,
          347,
          312,
          274,
          237,
          278,
          284,
          277,
          317,
          313,
          318,
          374,
          413,
          405,
          355,
          306,
          271,
          306,
          315,
          301,
          356,
          348,
          355,
          422,
          465,
          467,
          404,
          347,
          305,
          336,
          340,
          318,
          362,
          348,
          363,
          435,
          491,
          505,
          404,
          359,
          310,
          337,
          360,
          342,
          406,
          396,
          420,
          472,
          548,
          559,
          463,
          407,
          362,
          405,
          417,
          391,
          419,
          461,
          472,
          535,
          622,
          606,
          508,
          461,
          390,
          432
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "orientation": "h",
         "title": {
          "text": ""
         },
         "tracegroupgap": 0,
         "y": 1.02
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "font": {
           "size": 18
          },
          "xaxis": {
           "title": {
            "font": {
             "size": 24
            }
           }
          },
          "yaxis": {
           "title": {
            "font": {
             "size": 24
            }
           }
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Month"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Passengers"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set fraction: 0.24475524475524477\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # How to use PyTorch LSTMs for time series regression\n",
    "\n",
    "# %% [markdown]\n",
    "# # Data\n",
    "\n",
    "# %% [markdown]\n",
    "# 1. Download the Air Passengers data.\n",
    "# 2. Load the Air Passengers data into a DataFrame.\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data-sets/air_passengers.csv\", index_col=\"Month\", parse_dates=True)\n",
    "df.rename(columns={'#Passengers': 'Passengers'}, inplace=True)\n",
    "\n",
    "# %%\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "plot_template = dict(\n",
    "    layout=go.Layout({\n",
    "        \"font_size\": 18,\n",
    "        \"xaxis_title_font_size\": 24,\n",
    "        \"yaxis_title_font_size\": 24})\n",
    ")\n",
    "\n",
    "fig = px.line(df, labels=dict(index=\"Date\", value=\"Passengers\"))\n",
    "fig.update_layout(\n",
    "  template=plot_template, legend=dict(orientation='h', y=1.02, title_text=\"\")\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Create the target variable\n",
    "\n",
    "# %%\n",
    "forecast_lead = 1\n",
    "target = f\"lead{forecast_lead}\"\n",
    "\n",
    "df[target] = df[\"Passengers\"].shift(-forecast_lead)\n",
    "df = df.iloc[:-forecast_lead]\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Create a hold-out test set and preprocess the data\n",
    "\n",
    "# %%\n",
    "test_start = \"1958-01-01\"\n",
    "\n",
    "df_train = df.loc[:test_start].copy()\n",
    "df_test = df.loc[test_start:].copy()\n",
    "\n",
    "print(\"Test set fraction:\", len(df_test) / len(df))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Standardize the features and target, based on the training set\n",
    "\n",
    "# %%\n",
    "target_mean = df_train[target].mean()\n",
    "target_stdev = df_train[target].std()\n",
    "\n",
    "df_train[\"Passengers\"] = (df_train[\"Passengers\"] - target_mean) / target_stdev\n",
    "df_test[\"Passengers\"] = (df_test[\"Passengers\"] - target_mean) / target_stdev\n",
    "\n",
    "df_train[target] = (df_train[target] - target_mean) / target_stdev\n",
    "df_test[target] = (df_test[target] - target_mean) / target_stdev\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Create datasets that PyTorch `DataLoader` can work with\n",
    "\n",
    "# %%\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, dataframe, target, sequence_length=5):\n",
    "        self.target = target\n",
    "        self.sequence_length = sequence_length\n",
    "        self.y = torch.tensor(dataframe[self.target].values).float()\n",
    "        self.X = torch.tensor(dataframe['Passengers'].values).float().unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, i): \n",
    "        if i >= self.sequence_length - 1:\n",
    "            i_start = i - self.sequence_length + 1\n",
    "            x = self.X[i_start:(i + 1), :]\n",
    "        else:\n",
    "            padding = self.X[0].repeat(self.sequence_length - i - 1, 1)\n",
    "            x = self.X[0:(i + 1), :]\n",
    "            x = torch.cat((padding, x), 0)\n",
    "\n",
    "        return x, self.y[i]\n",
    "        \n",
    "# Continue the rest of the code as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: torch.Size([3, 3, 1])\n",
      "Target shape: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Create the datasets and data loaders\n",
    "\n",
    "# %%\n",
    "from bayes_opt import BayesianOptimization, UtilityFunction\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(101)\n",
    "\n",
    "batch_size = 3\n",
    "sequence_length = 3\n",
    "\n",
    "train_dataset = SequenceDataset(\n",
    "    df_train,\n",
    "    target=target,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "test_dataset = SequenceDataset(\n",
    "    df_test,\n",
    "    target=target,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "X, y = next(iter(train_loader))\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "\n",
    "# %% [markdown]\n",
    "# # The model and learning algorithm\n",
    "\n",
    "# %%\n",
    "from torch import nn\n",
    "\n",
    "class ShallowRegressionLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=1,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True,\n",
    "            num_layers=self.num_layers\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(in_features=self.hidden_size, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).requires_grad_()\n",
    "        \n",
    "        _, (hn, _) = self.lstm(x, (h0, c0))\n",
    "        out = self.linear(hn[0]).flatten()\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... | learni... | num_hi... | num_la... | weight... |\n",
      "-------------------------------------------------------------------------------------\n",
      "Train loss: 0.8968461740107553\n",
      "Test loss: 6.890447437763214\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-6.89    \u001b[0m | \u001b[0m46.04    \u001b[0m | \u001b[0m-2.839   \u001b[0m | \u001b[0m1.007    \u001b[0m | \u001b[0m1.907    \u001b[0m | \u001b[0m-4.56    \u001b[0m |\n",
      "Train loss: 1.0270966721849668\n",
      "Test loss: 6.815695971250534\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m-6.816   \u001b[0m | \u001b[95m10.97    \u001b[0m | \u001b[95m-4.441   \u001b[0m | \u001b[95m22.77    \u001b[0m | \u001b[95m2.19     \u001b[0m | \u001b[95m-3.384   \u001b[0m |\n",
      "Train loss: 0.9842816997520827\n",
      "Test loss: 6.416813999414444\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m-6.417   \u001b[0m | \u001b[95m46.27    \u001b[0m | \u001b[95m-2.944   \u001b[0m | \u001b[95m13.88    \u001b[0m | \u001b[95m3.634    \u001b[0m | \u001b[95m-4.918   \u001b[0m |\n",
      "Train loss: 1.014196076103159\n",
      "Test loss: 5.432610432306926\n",
      "| \u001b[95m4        \u001b[0m | \u001b[95m-5.433   \u001b[0m | \u001b[95m73.41    \u001b[0m | \u001b[95m-3.748   \u001b[0m | \u001b[95m36.2     \u001b[0m | \u001b[95m1.421    \u001b[0m | \u001b[95m-4.406   \u001b[0m |\n",
      "Train loss: 0.5261348792527979\n",
      "Test loss: 1.037322151164214\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m-1.037   \u001b[0m | \u001b[95m87.48    \u001b[0m | \u001b[95m-2.095   \u001b[0m | \u001b[95m20.75    \u001b[0m | \u001b[95m3.077    \u001b[0m | \u001b[95m-2.371   \u001b[0m |\n",
      "Train loss: 0.6471330212441752\n",
      "Test loss: 1.156525043149789\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-1.157   \u001b[0m | \u001b[0m87.81    \u001b[0m | \u001b[0m-2.087   \u001b[0m | \u001b[0m21.49    \u001b[0m | \u001b[0m2.969    \u001b[0m | \u001b[0m-2.093   \u001b[0m |\n",
      "Train loss: 0.9506507816951018\n",
      "Test loss: 5.581307460864385\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-5.581   \u001b[0m | \u001b[0m101.5    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m3.842    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 0.8909136087105081\n",
      "Test loss: 5.483627676963806\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-5.484   \u001b[0m | \u001b[0m77.89    \u001b[0m | \u001b[0m-5.0     \u001b[0m | \u001b[0m11.63    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.9506043936755206\n",
      "Test loss: 4.8788602103789644\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-4.879   \u001b[0m | \u001b[0m93.43    \u001b[0m | \u001b[0m-5.0     \u001b[0m | \u001b[0m18.75    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 0.4405005139847777\n",
      "Test loss: 1.087679826033612\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-1.088   \u001b[0m | \u001b[0m82.99    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m22.96    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-3.742   \u001b[0m |\n",
      "Train loss: 0.7383827929561203\n",
      "Test loss: 3.4046269208192825\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-3.405   \u001b[0m | \u001b[0m90.08    \u001b[0m | \u001b[0m-2.711   \u001b[0m | \u001b[0m33.58    \u001b[0m | \u001b[0m3.951    \u001b[0m | \u001b[0m-4.122   \u001b[0m |\n",
      "Train loss: 1.083349132054561\n",
      "Test loss: 6.086061050494512\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-6.086   \u001b[0m | \u001b[0m84.78    \u001b[0m | \u001b[0m-5.0     \u001b[0m | \u001b[0m22.4     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 0.5023644551936839\n",
      "Test loss: 2.031081390877565\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-2.031   \u001b[0m | \u001b[0m84.72    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m21.43    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.36034296032645413\n",
      "Test loss: 0.7121998239308596\n",
      "| \u001b[95m14       \u001b[0m | \u001b[95m-0.7122  \u001b[0m | \u001b[95m84.05    \u001b[0m | \u001b[95m-2.0     \u001b[0m | \u001b[95m25.78    \u001b[0m | \u001b[95m4.0      \u001b[0m | \u001b[95m-2.386   \u001b[0m |\n",
      "Train loss: 0.35410581332807606\n",
      "Test loss: 0.7392480621735255\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-0.7392  \u001b[0m | \u001b[0m80.06    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m25.67    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.089   \u001b[0m |\n",
      "Train loss: 0.37237790322585684\n",
      "Test loss: 1.8495233251402776\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m-1.85    \u001b[0m | \u001b[0m81.57    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m28.62    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 0.4087890819017146\n",
      "Test loss: 1.7221303954720497\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m-1.722   \u001b[0m | \u001b[0m76.41    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m23.15    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 0.3631365146689318\n",
      "Test loss: 0.8438808831075827\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m-0.8439  \u001b[0m | \u001b[0m70.17    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m24.22    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.3611382194920569\n",
      "Test loss: 1.1940272394567728\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m-1.194   \u001b[0m | \u001b[0m66.74    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m20.71    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 0.960785066155163\n",
      "Test loss: 4.431325152516365\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m-4.431   \u001b[0m | \u001b[0m63.47    \u001b[0m | \u001b[0m-3.893   \u001b[0m | \u001b[0m25.08    \u001b[0m | \u001b[0m3.09     \u001b[0m | \u001b[0m-2.477   \u001b[0m |\n",
      "Train loss: 1.023173323454889\n",
      "Test loss: 6.991388827562332\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m-6.991   \u001b[0m | \u001b[0m71.0     \u001b[0m | \u001b[0m-3.403   \u001b[0m | \u001b[0m20.26    \u001b[0m | \u001b[0m3.34     \u001b[0m | \u001b[0m-2.119   \u001b[0m |\n",
      "Train loss: 0.43985973007825985\n",
      "Test loss: 1.9163765522340934\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m-1.916   \u001b[0m | \u001b[0m72.47    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m26.75    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-3.261   \u001b[0m |\n",
      "Train loss: 0.48646403446390823\n",
      "Test loss: 1.4414435178041458\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m-1.441   \u001b[0m | \u001b[0m68.95    \u001b[0m | \u001b[0m-2.203   \u001b[0m | \u001b[0m25.51    \u001b[0m | \u001b[0m3.161    \u001b[0m | \u001b[0m-4.865   \u001b[0m |\n",
      "Train loss: 0.4352634076935214\n",
      "Test loss: 1.1376006255547206\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m-1.138   \u001b[0m | \u001b[0m79.49    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m21.92    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.4252812034337202\n",
      "Test loss: 1.5389945767819881\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m-1.539   \u001b[0m | \u001b[0m81.82    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m26.94    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.9239600555140626\n",
      "Test loss: 5.803718666235606\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m-5.804   \u001b[0m | \u001b[0m81.92    \u001b[0m | \u001b[0m-5.0     \u001b[0m | \u001b[0m27.81    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.4678941981967639\n",
      "Test loss: 0.8461557738482952\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m-0.8462  \u001b[0m | \u001b[0m79.93    \u001b[0m | \u001b[0m-2.257   \u001b[0m | \u001b[0m24.51    \u001b[0m | \u001b[0m1.249    \u001b[0m | \u001b[0m-3.679   \u001b[0m |\n",
      "Train loss: 0.4598940897330239\n",
      "Test loss: 1.9391209023694198\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m-1.939   \u001b[0m | \u001b[0m69.56    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m26.72    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.8350259530785922\n",
      "Test loss: 4.8763472239176435\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m-4.876   \u001b[0m | \u001b[0m62.66    \u001b[0m | \u001b[0m-2.864   \u001b[0m | \u001b[0m16.57    \u001b[0m | \u001b[0m2.316    \u001b[0m | \u001b[0m-4.772   \u001b[0m |\n",
      "Train loss: 0.42445941738205384\n",
      "Test loss: 1.2422411624963086\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m-1.242   \u001b[0m | \u001b[0m75.78    \u001b[0m | \u001b[0m-2.035   \u001b[0m | \u001b[0m26.32    \u001b[0m | \u001b[0m1.774    \u001b[0m | \u001b[0m-2.025   \u001b[0m |\n",
      "Train loss: 0.41831364608495625\n",
      "Test loss: 1.3120699270317953\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m-1.312   \u001b[0m | \u001b[0m77.77    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m27.66    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 0.45108344529226824\n",
      "Test loss: 1.146190700121224\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m-1.146   \u001b[0m | \u001b[0m88.4     \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m16.09    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.7028314842767006\n",
      "Test loss: 2.718362179895242\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m-2.718   \u001b[0m | \u001b[0m87.68    \u001b[0m | \u001b[0m-2.253   \u001b[0m | \u001b[0m11.51    \u001b[0m | \u001b[0m2.234    \u001b[0m | \u001b[0m-4.241   \u001b[0m |\n",
      "Train loss: 0.9774493260963543\n",
      "Test loss: 6.575486123561859\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m-6.575   \u001b[0m | \u001b[0m33.01    \u001b[0m | \u001b[0m-4.716   \u001b[0m | \u001b[0m63.79    \u001b[0m | \u001b[0m2.667    \u001b[0m | \u001b[0m-2.642   \u001b[0m |\n",
      "Train loss: 0.9900882699577188\n",
      "Test loss: 6.0282392501831055\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m-6.028   \u001b[0m | \u001b[0m108.8    \u001b[0m | \u001b[0m-4.292   \u001b[0m | \u001b[0m63.94    \u001b[0m | \u001b[0m3.235    \u001b[0m | \u001b[0m-2.512   \u001b[0m |\n",
      "Train loss: 0.44938990466989953\n",
      "Test loss: 1.5086642721047003\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m-1.509   \u001b[0m | \u001b[0m1.04     \u001b[0m | \u001b[0m-2.124   \u001b[0m | \u001b[0m59.61    \u001b[0m | \u001b[0m1.282    \u001b[0m | \u001b[0m-4.684   \u001b[0m |\n",
      "Train loss: 0.9832507240007052\n",
      "Test loss: 5.874906033277512\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m-5.875   \u001b[0m | \u001b[0m2.171    \u001b[0m | \u001b[0m-4.26    \u001b[0m | \u001b[0m54.72    \u001b[0m | \u001b[0m2.12     \u001b[0m | \u001b[0m-3.023   \u001b[0m |\n",
      "Train loss: 0.3714220807132487\n",
      "Test loss: 0.6781925254811844\n",
      "| \u001b[95m38       \u001b[0m | \u001b[95m-0.6782  \u001b[0m | \u001b[95m2.577    \u001b[0m | \u001b[95m-2.149   \u001b[0m | \u001b[95m63.78    \u001b[0m | \u001b[95m3.59     \u001b[0m | \u001b[95m-4.904   \u001b[0m |\n",
      "Train loss: 0.8891540321999708\n",
      "Test loss: 4.254142706592877\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m-4.254   \u001b[0m | \u001b[0m5.887    \u001b[0m | \u001b[0m-3.123   \u001b[0m | \u001b[0m62.88    \u001b[0m | \u001b[0m1.297    \u001b[0m | \u001b[0m-4.221   \u001b[0m |\n",
      "Train loss: 1.037758474842318\n",
      "Test loss: 5.511774857838948\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m-5.512   \u001b[0m | \u001b[0m1.244    \u001b[0m | \u001b[0m-4.956   \u001b[0m | \u001b[0m63.44    \u001b[0m | \u001b[0m3.73     \u001b[0m | \u001b[0m-3.067   \u001b[0m |\n",
      "Train loss: 1.0390497997805879\n",
      "Test loss: 5.815333674351375\n",
      "| \u001b[0m41       \u001b[0m | \u001b[0m-5.815   \u001b[0m | \u001b[0m69.59    \u001b[0m | \u001b[0m-5.0     \u001b[0m | \u001b[0m26.64    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.9999404759020418\n",
      "Test loss: 6.029741297165553\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m-6.03    \u001b[0m | \u001b[0m77.83    \u001b[0m | \u001b[0m-4.172   \u001b[0m | \u001b[0m25.15    \u001b[0m | \u001b[0m3.233    \u001b[0m | \u001b[0m-4.928   \u001b[0m |\n",
      "Train loss: 0.4735297424265662\n",
      "Test loss: 1.9212679527699947\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m-1.921   \u001b[0m | \u001b[0m81.74    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m24.02    \u001b[0m | \u001b[0m2.551    \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.4804343821203991\n",
      "Test loss: 1.1678613796830177\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m-1.168   \u001b[0m | \u001b[0m77.49    \u001b[0m | \u001b[0m-2.191   \u001b[0m | \u001b[0m28.98    \u001b[0m | \u001b[0m1.264    \u001b[0m | \u001b[0m-2.14    \u001b[0m |\n",
      "Train loss: 0.36366345179644793\n",
      "Test loss: 1.3869560174643993\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m-1.387   \u001b[0m | \u001b[0m78.69    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m26.16    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.41996653866324873\n",
      "Test loss: 1.4894012237588565\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m-1.489   \u001b[0m | \u001b[0m82.14    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m25.46    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-4.72    \u001b[0m |\n",
      "Train loss: 0.4061067181509979\n",
      "Test loss: 1.1916170675928395\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m-1.192   \u001b[0m | \u001b[0m89.65    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m19.27    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.44036151798806983\n",
      "Test loss: 1.1840709050496419\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m-1.184   \u001b[0m | \u001b[0m78.07    \u001b[0m | \u001b[0m-2.066   \u001b[0m | \u001b[0m21.41    \u001b[0m | \u001b[0m1.274    \u001b[0m | \u001b[0m-4.199   \u001b[0m |\n",
      "Train loss: 0.31222849087537946\n",
      "Test loss: 1.166259032053252\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m-1.166   \u001b[0m | \u001b[0m87.44    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m26.16    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-3.717   \u001b[0m |\n",
      "Train loss: 0.5979097976374466\n",
      "Test loss: 1.7801206403722365\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m-1.78    \u001b[0m | \u001b[0m84.55    \u001b[0m | \u001b[0m-2.15    \u001b[0m | \u001b[0m16.04    \u001b[0m | \u001b[0m3.956    \u001b[0m | \u001b[0m-2.595   \u001b[0m |\n",
      "Train loss: 0.4710907078178197\n",
      "Test loss: 1.098254218697548\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m-1.098   \u001b[0m | \u001b[0m89.0     \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m17.31    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.517246362381942\n",
      "Test loss: 1.1149527058005333\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m-1.115   \u001b[0m | \u001b[0m92.62    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m13.91    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.36360683941559213\n",
      "Test loss: 1.1993605711807807\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m-1.199   \u001b[0m | \u001b[0m91.19    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m26.19    \u001b[0m | \u001b[0m1.002    \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.40860934253479986\n",
      "Test loss: 1.9741180948913097\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m-1.974   \u001b[0m | \u001b[0m87.22    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m28.57    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.4076346513097264\n",
      "Test loss: 1.9529706699152787\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m-1.953   \u001b[0m | \u001b[0m93.1     \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m26.87    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-4.743   \u001b[0m |\n",
      "Train loss: 0.9742305381475268\n",
      "Test loss: 5.794697205225627\n",
      "| \u001b[0m56       \u001b[0m | \u001b[0m-5.795   \u001b[0m | \u001b[0m93.68    \u001b[0m | \u001b[0m-3.349   \u001b[0m | \u001b[0m9.57     \u001b[0m | \u001b[0m1.486    \u001b[0m | \u001b[0m-2.431   \u001b[0m |\n",
      "Train loss: 0.42408048285555244\n",
      "Test loss: 1.6179049114386241\n",
      "| \u001b[0m57       \u001b[0m | \u001b[0m-1.618   \u001b[0m | \u001b[0m91.65    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m23.47    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.4402026532066835\n",
      "Test loss: 1.0088282143697143\n",
      "| \u001b[0m58       \u001b[0m | \u001b[0m-1.009   \u001b[0m | \u001b[0m80.12    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m18.91    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 1.1866780189243522\n",
      "Test loss: 6.005738168954849\n",
      "| \u001b[0m59       \u001b[0m | \u001b[0m-6.006   \u001b[0m | \u001b[0m96.38    \u001b[0m | \u001b[0m-4.559   \u001b[0m | \u001b[0m26.59    \u001b[0m | \u001b[0m1.105    \u001b[0m | \u001b[0m-2.335   \u001b[0m |\n",
      "Train loss: 0.8786734332129158\n",
      "Test loss: 4.098707397778829\n",
      "| \u001b[0m60       \u001b[0m | \u001b[0m-4.099   \u001b[0m | \u001b[0m64.41    \u001b[0m | \u001b[0m-3.025   \u001b[0m | \u001b[0m63.73    \u001b[0m | \u001b[0m1.661    \u001b[0m | \u001b[0m-4.863   \u001b[0m |\n",
      "Train loss: 0.3939274480830677\n",
      "Test loss: 1.0114837568253279\n",
      "| \u001b[0m61       \u001b[0m | \u001b[0m-1.011   \u001b[0m | \u001b[0m67.18    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m22.94    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 0.4119217375519912\n",
      "Test loss: 1.5886043285330136\n",
      "| \u001b[0m62       \u001b[0m | \u001b[0m-1.589   \u001b[0m | \u001b[0m34.66    \u001b[0m | \u001b[0m-2.093   \u001b[0m | \u001b[0m38.05    \u001b[0m | \u001b[0m3.999    \u001b[0m | \u001b[0m-2.146   \u001b[0m |\n",
      "Train loss: 0.8776625497518359\n",
      "Test loss: 4.513782064119975\n",
      "| \u001b[0m63       \u001b[0m | \u001b[0m-4.514   \u001b[0m | \u001b[0m39.49    \u001b[0m | \u001b[0m-2.998   \u001b[0m | \u001b[0m38.62    \u001b[0m | \u001b[0m1.842    \u001b[0m | \u001b[0m-2.348   \u001b[0m |\n",
      "Train loss: 0.24967721504838886\n",
      "Test loss: 0.9006567591180404\n",
      "| \u001b[0m64       \u001b[0m | \u001b[0m-0.9007  \u001b[0m | \u001b[0m29.79    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m37.49    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.7619144114086757\n",
      "Test loss: 3.1166119376818338\n",
      "| \u001b[0m65       \u001b[0m | \u001b[0m-3.117   \u001b[0m | \u001b[0m31.34    \u001b[0m | \u001b[0m-2.736   \u001b[0m | \u001b[0m33.4     \u001b[0m | \u001b[0m3.527    \u001b[0m | \u001b[0m-2.474   \u001b[0m |\n",
      "Train loss: 0.3644908314627419\n",
      "Test loss: 2.228902588287989\n",
      "| \u001b[0m66       \u001b[0m | \u001b[0m-2.229   \u001b[0m | \u001b[0m30.92    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m41.56    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.3746154259739293\n",
      "Test loss: 1.8021843880414963\n",
      "| \u001b[0m67       \u001b[0m | \u001b[0m-1.802   \u001b[0m | \u001b[0m25.4     \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m38.27    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 1.0932570493943687\n",
      "Test loss: 6.394622246424357\n",
      "| \u001b[0m68       \u001b[0m | \u001b[0m-6.395   \u001b[0m | \u001b[0m29.37    \u001b[0m | \u001b[0m-5.0     \u001b[0m | \u001b[0m38.45    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 0.3310933659306249\n",
      "Test loss: 0.7473618021855751\n",
      "| \u001b[0m69       \u001b[0m | \u001b[0m-0.7474  \u001b[0m | \u001b[0m71.97    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m24.49    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 0.36880186512260826\n",
      "Test loss: 1.1375571265816689\n",
      "| \u001b[0m70       \u001b[0m | \u001b[0m-1.138   \u001b[0m | \u001b[0m23.75    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m33.17    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.3791240748722811\n",
      "Test loss: 1.4789681248366833\n",
      "| \u001b[0m71       \u001b[0m | \u001b[0m-1.479   \u001b[0m | \u001b[0m21.3     \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m35.35    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 1.0331012659479637\n",
      "Test loss: 6.659599492947261\n",
      "| \u001b[0m72       \u001b[0m | \u001b[0m-6.66    \u001b[0m | \u001b[0m20.19    \u001b[0m | \u001b[0m-5.0     \u001b[0m | \u001b[0m33.15    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.5052569545459354\n",
      "Test loss: 1.254363453015685\n",
      "| \u001b[0m73       \u001b[0m | \u001b[0m-1.254   \u001b[0m | \u001b[0m25.51    \u001b[0m | \u001b[0m-2.124   \u001b[0m | \u001b[0m32.03    \u001b[0m | \u001b[0m1.468    \u001b[0m | \u001b[0m-3.619   \u001b[0m |\n",
      "Train loss: 0.6197074376852125\n",
      "Test loss: 1.9804806920389335\n",
      "| \u001b[0m74       \u001b[0m | \u001b[0m-1.98    \u001b[0m | \u001b[0m25.31    \u001b[0m | \u001b[0m-2.491   \u001b[0m | \u001b[0m28.06    \u001b[0m | \u001b[0m2.465    \u001b[0m | \u001b[0m-2.053   \u001b[0m |\n",
      "Train loss: 0.9178947235986188\n",
      "Test loss: 4.547277723749478\n",
      "| \u001b[0m75       \u001b[0m | \u001b[0m-4.547   \u001b[0m | \u001b[0m25.69    \u001b[0m | \u001b[0m-3.147   \u001b[0m | \u001b[0m35.5     \u001b[0m | \u001b[0m1.89     \u001b[0m | \u001b[0m-2.337   \u001b[0m |\n",
      "Train loss: 0.5064510910998326\n",
      "Test loss: 0.8597872865696748\n",
      "| \u001b[0m76       \u001b[0m | \u001b[0m-0.8598  \u001b[0m | \u001b[0m80.35    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m18.55    \u001b[0m | \u001b[0m1.744    \u001b[0m | \u001b[0m-2.174   \u001b[0m |\n",
      "Train loss: 0.4534118353716425\n",
      "Test loss: 0.9694468254844347\n",
      "| \u001b[0m77       \u001b[0m | \u001b[0m-0.9694  \u001b[0m | \u001b[0m92.41    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m16.97    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.4617664812296327\n",
      "Test loss: 1.169696155935526\n",
      "| \u001b[0m78       \u001b[0m | \u001b[0m-1.17    \u001b[0m | \u001b[0m77.97    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m18.14    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.205   \u001b[0m |\n",
      "Train loss: 0.46564004629790606\n",
      "Test loss: 1.4848891521493595\n",
      "| \u001b[0m79       \u001b[0m | \u001b[0m-1.485   \u001b[0m | \u001b[0m22.74    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m30.84    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.32411111326183417\n",
      "Test loss: 1.1912956566860278\n",
      "| \u001b[0m80       \u001b[0m | \u001b[0m-1.191   \u001b[0m | \u001b[0m20.4     \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m40.34    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.33689093783598495\n",
      "Test loss: 0.7223709219445785\n",
      "| \u001b[0m81       \u001b[0m | \u001b[0m-0.7224  \u001b[0m | \u001b[0m23.88    \u001b[0m | \u001b[0m-2.128   \u001b[0m | \u001b[0m43.97    \u001b[0m | \u001b[0m2.242    \u001b[0m | \u001b[0m-2.245   \u001b[0m |\n",
      "Train loss: 0.46486216487765714\n",
      "Test loss: 0.9534091176465154\n",
      "| \u001b[0m82       \u001b[0m | \u001b[0m-0.9534  \u001b[0m | \u001b[0m19.76    \u001b[0m | \u001b[0m-2.357   \u001b[0m | \u001b[0m44.98    \u001b[0m | \u001b[0m1.415    \u001b[0m | \u001b[0m-2.374   \u001b[0m |\n",
      "Train loss: 1.0312158136181786\n",
      "Test loss: 6.089818100134532\n",
      "| \u001b[0m83       \u001b[0m | \u001b[0m-6.09    \u001b[0m | \u001b[0m20.99    \u001b[0m | \u001b[0m-4.976   \u001b[0m | \u001b[0m43.0     \u001b[0m | \u001b[0m3.736    \u001b[0m | \u001b[0m-3.588   \u001b[0m |\n",
      "Train loss: 0.33047050683180224\n",
      "Test loss: 0.7509678068260351\n",
      "| \u001b[0m84       \u001b[0m | \u001b[0m-0.751   \u001b[0m | \u001b[0m22.9     \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m47.28    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.4183233142201159\n",
      "Test loss: 1.7739180053273838\n",
      "| \u001b[0m85       \u001b[0m | \u001b[0m-1.774   \u001b[0m | \u001b[0m26.9     \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m45.99    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.3947703025706515\n",
      "Test loss: 1.7080239119629066\n",
      "| \u001b[0m86       \u001b[0m | \u001b[0m-1.708   \u001b[0m | \u001b[0m18.74    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m48.98    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.4103495560687136\n",
      "Test loss: 1.75734868273139\n",
      "| \u001b[0m87       \u001b[0m | \u001b[0m-1.757   \u001b[0m | \u001b[0m15.45    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m43.81    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.3606551924273623\n",
      "Test loss: 2.265893943607807\n",
      "| \u001b[0m88       \u001b[0m | \u001b[0m-2.266   \u001b[0m | \u001b[0m24.25    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m49.74    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.30738095335058263\n",
      "Test loss: 1.3894951554636161\n",
      "| \u001b[0m89       \u001b[0m | \u001b[0m-1.389   \u001b[0m | \u001b[0m25.46    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m41.46    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.37758080151586515\n",
      "Test loss: 2.141899893681208\n",
      "| \u001b[0m90       \u001b[0m | \u001b[0m-2.142   \u001b[0m | \u001b[0m15.84    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m38.38    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.8753371319255313\n",
      "Test loss: 4.197101041674614\n",
      "| \u001b[0m91       \u001b[0m | \u001b[0m-4.197   \u001b[0m | \u001b[0m13.17    \u001b[0m | \u001b[0m-2.92    \u001b[0m | \u001b[0m48.72    \u001b[0m | \u001b[0m2.648    \u001b[0m | \u001b[0m-4.785   \u001b[0m |\n",
      "Train loss: 0.41474685764468805\n",
      "Test loss: 1.16172469034791\n",
      "| \u001b[0m92       \u001b[0m | \u001b[0m-1.162   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m64.0     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 1.002078957503309\n",
      "Test loss: 6.302190274000168\n",
      "| \u001b[0m93       \u001b[0m | \u001b[0m-6.302   \u001b[0m | \u001b[0m20.58    \u001b[0m | \u001b[0m-3.592   \u001b[0m | \u001b[0m54.57    \u001b[0m | \u001b[0m1.126    \u001b[0m | \u001b[0m-2.326   \u001b[0m |\n",
      "Train loss: 0.3660651516118968\n",
      "Test loss: 1.9093090519309044\n",
      "| \u001b[0m94       \u001b[0m | \u001b[0m-1.909   \u001b[0m | \u001b[0m30.06    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m24.71    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 0.4743247398905255\n",
      "Test loss: 1.259781885581712\n",
      "| \u001b[0m95       \u001b[0m | \u001b[0m-1.26    \u001b[0m | \u001b[0m25.57    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m20.59    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 0.9434776573970511\n",
      "Test loss: 5.808391451835632\n",
      "| \u001b[0m96       \u001b[0m | \u001b[0m-5.808   \u001b[0m | \u001b[0m29.02    \u001b[0m | \u001b[0m-3.77    \u001b[0m | \u001b[0m19.62    \u001b[0m | \u001b[0m2.91     \u001b[0m | \u001b[0m-2.364   \u001b[0m |\n",
      "Train loss: 0.3477553345539884\n",
      "Test loss: 0.98372073409458\n",
      "| \u001b[0m97       \u001b[0m | \u001b[0m-0.9837  \u001b[0m | \u001b[0m24.26    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m30.29    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 0.6678598422204723\n",
      "Test loss: 2.9393789718548455\n",
      "| \u001b[0m98       \u001b[0m | \u001b[0m-2.939   \u001b[0m | \u001b[0m22.85    \u001b[0m | \u001b[0m-2.508   \u001b[0m | \u001b[0m25.0     \u001b[0m | \u001b[0m1.608    \u001b[0m | \u001b[0m-4.586   \u001b[0m |\n",
      "Train loss: 0.6188894136229882\n",
      "Test loss: 1.812721511349082\n",
      "| \u001b[0m99       \u001b[0m | \u001b[0m-1.813   \u001b[0m | \u001b[0m23.03    \u001b[0m | \u001b[0m-2.312   \u001b[0m | \u001b[0m17.4     \u001b[0m | \u001b[0m1.38     \u001b[0m | \u001b[0m-4.247   \u001b[0m |\n",
      "Train loss: 0.9535793168721972\n",
      "Test loss: 5.253864179054896\n",
      "| \u001b[0m100      \u001b[0m | \u001b[0m-5.254   \u001b[0m | \u001b[0m21.08    \u001b[0m | \u001b[0m-3.452   \u001b[0m | \u001b[0m11.21    \u001b[0m | \u001b[0m2.222    \u001b[0m | \u001b[0m-4.668   \u001b[0m |\n",
      "Train loss: 0.3723879719304072\n",
      "Test loss: 1.3765052606662114\n",
      "| \u001b[0m101      \u001b[0m | \u001b[0m-1.377   \u001b[0m | \u001b[0m23.29    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m45.81    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 0.38987673904646086\n",
      "Test loss: 1.601313189913829\n",
      "| \u001b[0m102      \u001b[0m | \u001b[0m-1.601   \u001b[0m | \u001b[0m80.64    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m32.33    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 0.2704807229944178\n",
      "Test loss: 0.6317705710728964\n",
      "| \u001b[95m103      \u001b[0m | \u001b[95m-0.6318  \u001b[0m | \u001b[95m8.39     \u001b[0m | \u001b[95m-2.0     \u001b[0m | \u001b[95m39.5     \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m-2.0     \u001b[0m |\n",
      "Train loss: 0.9096360492777249\n",
      "Test loss: 5.23088464140892\n",
      "| \u001b[0m104      \u001b[0m | \u001b[0m-5.231   \u001b[0m | \u001b[0m4.768    \u001b[0m | \u001b[0m-3.312   \u001b[0m | \u001b[0m38.75    \u001b[0m | \u001b[0m2.565    \u001b[0m | \u001b[0m-2.209   \u001b[0m |\n",
      "Train loss: 0.43119472159525835\n",
      "Test loss: 1.946069670220216\n",
      "| \u001b[0m105      \u001b[0m | \u001b[0m-1.946   \u001b[0m | \u001b[0m11.06    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m40.58    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m-3.874   \u001b[0m |\n",
      "=====================================================================================\n",
      "{'target': -0.6317705710728964, 'params': {'batch_size': 8.389685273141586, 'learning_rate_log': -2.0, 'num_hidden_size': 39.501642471411316, 'num_layers': 1.0, 'weight_decay': -2.0}}\n"
     ]
    }
   ],
   "source": [
    "def train_model(data_loader, model, loss_function, optimizer):\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for X, y in data_loader:\n",
    "        output = model(X)\n",
    "        loss = loss_function(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Train loss: {avg_loss}\")\n",
    "    return avg_loss\n",
    "\n",
    "def test_model(data_loader, model, loss_function):\n",
    "    \n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            output = model(X)\n",
    "            total_loss += loss_function(output, y).item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Test loss: {avg_loss}\")\n",
    "    return avg_loss\n",
    "\n",
    "# Define the function to be optimized\n",
    "def evaluate_model(learning_rate_log, num_hidden_size, num_layers, weight_decay, batch_size):\n",
    "    learning_rate = 10 ** learning_rate_log\n",
    "    num_hidden_size = int(num_hidden_size)\n",
    "    num_layers = int(num_layers)\n",
    "    weight_decay = 10 ** weight_decay\n",
    "    batch_size = int(batch_size)\n",
    "\n",
    "    # Reinitialize the model with new parameters\n",
    "    model = ShallowRegressionLSTM(hidden_size=num_hidden_size, num_layers=num_layers)\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    # Train and test the model\n",
    "    train_model(train_loader, model, loss_function, optimizer)\n",
    "    test_loss = test_model(test_loader, model, loss_function)\n",
    "    \n",
    "    # Return the negative test loss because BayesianOptimization maximize the function\n",
    "    return -test_loss\n",
    "\n",
    "\n",
    "# Define the hyperparameters range\n",
    "hyperparameters_range = {\n",
    "    'learning_rate_log': (-5, -2),  # we optimize in log scale\n",
    "    'num_hidden_size': (1, 64),  # assuming 50 is a sensible upper limit\n",
    "    'num_layers': (2, 4),  # range of layers\n",
    "    'weight_decay': (-5, -2),  # weight decay in log scale\n",
    "    'batch_size': (1, len(df_train))\n",
    "}\n",
    "# Initialize the optimizer\n",
    "bayesian_optimizer = BayesianOptimization(\n",
    "    f=evaluate_model,\n",
    "    pbounds=hyperparameters_range,\n",
    "    verbose=2,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# Maximize the evaluation function\n",
    "bayesian_optimizer.maximize(init_points=5, n_iter=100)\n",
    "\n",
    "# Print the best parameters\n",
    "print(bayesian_optimizer.max)\n",
    "\n",
    "best_params = bayesian_optimizer.max['params']\n",
    "\n",
    "# Re-calculate the learning rate from its logarithm\n",
    "best_params['learning_rate_log'] = 10 ** best_params['learning_rate_log']\n",
    "\n",
    "# Ensure hidden_size and num_layers are integers\n",
    "best_params['num_hidden_size'] = int(round(best_params['num_hidden_size']))\n",
    "best_params['num_layers'] = int(round(best_params['num_layers']))\n",
    "\n",
    "# Train a new model with the best parameters\n",
    "model = ShallowRegressionLSTM(hidden_size=best_params['num_hidden_size'], num_layers=best_params['num_layers'])\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), best_params['learning_rate_log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained test\n",
      "--------\n",
      "Test loss: 5.675532301266988\n",
      "\n",
      "Epoch 0\n",
      "---------\n",
      "Train loss: 0.33454865333309547\n",
      "Test loss: 0.9358710683882236\n",
      "\n",
      "Epoch 1\n",
      "---------\n",
      "Train loss: 0.2090824622868535\n",
      "Test loss: 1.4455509303758542\n",
      "\n",
      "Epoch 2\n",
      "---------\n",
      "Train loss: 0.14185913677667142\n",
      "Test loss: 1.1227125364045303\n",
      "\n",
      "Epoch 3\n",
      "---------\n",
      "Train loss: 0.13467906301721577\n",
      "Test loss: 0.5936806909739971\n",
      "\n",
      "Epoch 4\n",
      "---------\n",
      "Train loss: 0.10098440851937551\n",
      "Test loss: 0.6597565139333407\n",
      "\n",
      "Epoch 5\n",
      "---------\n",
      "Train loss: 0.10572570948735685\n",
      "Test loss: 0.4322720095515251\n",
      "\n",
      "Epoch 6\n",
      "---------\n",
      "Train loss: 0.09098135460187001\n",
      "Test loss: 0.5132531126340231\n",
      "\n",
      "Epoch 7\n",
      "---------\n",
      "Train loss: 0.08649712298505914\n",
      "Test loss: 0.7881554116805395\n",
      "\n",
      "Epoch 8\n",
      "---------\n",
      "Train loss: 0.09137575713877497\n",
      "Test loss: 0.4290599711239338\n",
      "\n",
      "Epoch 9\n",
      "---------\n",
      "Train loss: 0.09552095436516243\n",
      "Test loss: 0.32599091654022533\n",
      "\n",
      "Epoch 10\n",
      "---------\n",
      "Train loss: 0.07924292931912115\n",
      "Test loss: 0.7487775832414627\n",
      "\n",
      "Epoch 11\n",
      "---------\n",
      "Train loss: 0.10376878432627465\n",
      "Test loss: 0.6003261071940263\n",
      "\n",
      "Epoch 12\n",
      "---------\n",
      "Train loss: 0.08268821824065133\n",
      "Test loss: 0.4281219889720281\n",
      "\n",
      "Epoch 13\n",
      "---------\n",
      "Train loss: 0.07684555359033717\n",
      "Test loss: 0.3294384367763996\n",
      "\n",
      "Epoch 14\n",
      "---------\n",
      "Train loss: 0.08057813638053532\n",
      "Test loss: 0.5689564136167368\n",
      "\n",
      "Epoch 15\n",
      "---------\n",
      "Train loss: 0.10472086311091443\n",
      "Test loss: 0.6681363297005495\n",
      "\n",
      "Epoch 16\n",
      "---------\n",
      "Train loss: 0.08187707467004657\n",
      "Test loss: 0.7955840316911539\n",
      "\n",
      "Epoch 17\n",
      "---------\n",
      "Train loss: 0.07759044915311844\n",
      "Test loss: 0.5544988295684258\n",
      "\n",
      "Epoch 18\n",
      "---------\n",
      "Train loss: 0.08129868907161762\n",
      "Test loss: 0.46599188695351285\n",
      "\n",
      "Epoch 19\n",
      "---------\n",
      "Train loss: 0.07284645922482014\n",
      "Test loss: 0.5133615601807833\n",
      "\n",
      "Epoch 20\n",
      "---------\n",
      "Train loss: 0.0776826313419922\n",
      "Test loss: 0.34389282142122585\n",
      "\n",
      "Epoch 21\n",
      "---------\n",
      "Train loss: 0.0768944098664498\n",
      "Test loss: 0.3822339816639821\n",
      "\n",
      "Epoch 22\n",
      "---------\n",
      "Train loss: 0.07482937519199441\n",
      "Test loss: 0.3169029721369346\n",
      "\n",
      "Epoch 23\n",
      "---------\n",
      "Train loss: 0.08087321589826732\n",
      "Test loss: 0.33367321640253067\n",
      "\n",
      "Epoch 24\n",
      "---------\n",
      "Train loss: 0.08038466711327233\n",
      "Test loss: 0.3310590696831544\n",
      "\n",
      "Epoch 25\n",
      "---------\n",
      "Train loss: 0.07457000745863125\n",
      "Test loss: 0.4330257164935271\n",
      "\n",
      "Epoch 26\n",
      "---------\n",
      "Train loss: 0.07117074359710976\n",
      "Test loss: 0.599295649677515\n",
      "\n",
      "Epoch 27\n",
      "---------\n",
      "Train loss: 0.07941459929822264\n",
      "Test loss: 0.3106992586205403\n",
      "\n",
      "Epoch 28\n",
      "---------\n",
      "Train loss: 0.08445326491837969\n",
      "Test loss: 0.4901563183714946\n",
      "\n",
      "Epoch 29\n",
      "---------\n",
      "Train loss: 0.07499208452390048\n",
      "Test loss: 0.38295443914830685\n",
      "\n",
      "Epoch 30\n",
      "---------\n",
      "Train loss: 0.07413134727362744\n",
      "Test loss: 0.43936928920447826\n",
      "\n",
      "Epoch 31\n",
      "---------\n",
      "Train loss: 0.082390334885064\n",
      "Test loss: 0.8040574590365092\n",
      "\n",
      "Epoch 32\n",
      "---------\n",
      "Train loss: 0.0866786458818997\n",
      "Test loss: 0.675007072587808\n",
      "\n",
      "Epoch 33\n",
      "---------\n",
      "Train loss: 0.07554567372111755\n",
      "Test loss: 0.4563864450901747\n",
      "\n",
      "Epoch 34\n",
      "---------\n",
      "Train loss: 0.06907060929586657\n",
      "Test loss: 0.4217485263943672\n",
      "\n",
      "Epoch 35\n",
      "---------\n",
      "Train loss: 0.07236202590079424\n",
      "Test loss: 0.3934250461558501\n",
      "\n",
      "Epoch 36\n",
      "---------\n",
      "Train loss: 0.07433982065885102\n",
      "Test loss: 0.6022090545545021\n",
      "\n",
      "Epoch 37\n",
      "---------\n",
      "Train loss: 0.08451790222898126\n",
      "Test loss: 0.6862806839247545\n",
      "\n",
      "Epoch 38\n",
      "---------\n",
      "Train loss: 0.07254353816293783\n",
      "Test loss: 0.3781137348463138\n",
      "\n",
      "Epoch 39\n",
      "---------\n",
      "Train loss: 0.07601635592574305\n",
      "Test loss: 0.39956032919387025\n",
      "\n",
      "Epoch 40\n",
      "---------\n",
      "Train loss: 0.07335628925923358\n",
      "Test loss: 0.4006856009364128\n",
      "\n",
      "Epoch 41\n",
      "---------\n",
      "Train loss: 0.06448716517676271\n",
      "Test loss: 0.5955687587459882\n",
      "\n",
      "Epoch 42\n",
      "---------\n",
      "Train loss: 0.08038677808174209\n",
      "Test loss: 0.8210157677531242\n",
      "\n",
      "Epoch 43\n",
      "---------\n",
      "Train loss: 0.08869523839471308\n",
      "Test loss: 0.7979085880021254\n",
      "\n",
      "Epoch 44\n",
      "---------\n",
      "Train loss: 0.09181373717414366\n",
      "Test loss: 0.5538539849221706\n",
      "\n",
      "Epoch 45\n",
      "---------\n",
      "Train loss: 0.07729336661538361\n",
      "Test loss: 0.48723462658623856\n",
      "\n",
      "Epoch 46\n",
      "---------\n",
      "Train loss: 0.07516913648391524\n",
      "Test loss: 0.5742630384241542\n",
      "\n",
      "Epoch 47\n",
      "---------\n",
      "Train loss: 0.07481759775278939\n",
      "Test loss: 0.4485325322796901\n",
      "\n",
      "Epoch 48\n",
      "---------\n",
      "Train loss: 0.07020431183077194\n",
      "Test loss: 0.5686581948151191\n",
      "\n",
      "Epoch 49\n",
      "---------\n",
      "Train loss: 0.07547643883908922\n",
      "Test loss: 0.6652312371879816\n",
      "\n",
      "Epoch 50\n",
      "---------\n",
      "Train loss: 0.07707481855853789\n",
      "Test loss: 0.5803523982564608\n",
      "\n",
      "Epoch 51\n",
      "---------\n",
      "Train loss: 0.0669052829628502\n",
      "Test loss: 0.4935569955656926\n",
      "\n",
      "Epoch 52\n",
      "---------\n",
      "Train loss: 0.08042663612679855\n",
      "Test loss: 0.4455252594004075\n",
      "\n",
      "Epoch 53\n",
      "---------\n",
      "Train loss: 0.07055761440455713\n",
      "Test loss: 0.5139099151516954\n",
      "\n",
      "Epoch 54\n",
      "---------\n",
      "Train loss: 0.061370685388258586\n",
      "Test loss: 0.6433833601574103\n",
      "\n",
      "Epoch 55\n",
      "---------\n",
      "Train loss: 0.07832938266565671\n",
      "Test loss: 0.4896615172425906\n",
      "\n",
      "Epoch 56\n",
      "---------\n",
      "Train loss: 0.069555761355504\n",
      "Test loss: 0.5186322964727879\n",
      "\n",
      "Epoch 57\n",
      "---------\n",
      "Train loss: 0.06728066200692509\n",
      "Test loss: 0.5970322067538897\n",
      "\n",
      "Epoch 58\n",
      "---------\n",
      "Train loss: 0.07576025109360549\n",
      "Test loss: 0.516558226197958\n",
      "\n",
      "Epoch 59\n",
      "---------\n",
      "Train loss: 0.0695146701874438\n",
      "Test loss: 0.5268092037489017\n",
      "\n",
      "Epoch 60\n",
      "---------\n",
      "Train loss: 0.07170609291642904\n",
      "Test loss: 0.5288964553425709\n",
      "\n",
      "Epoch 61\n",
      "---------\n",
      "Train loss: 0.06553008397286003\n",
      "Test loss: 0.4823009129613638\n",
      "\n",
      "Epoch 62\n",
      "---------\n",
      "Train loss: 0.06509661707221656\n",
      "Test loss: 0.6867419928312302\n",
      "\n",
      "Epoch 63\n",
      "---------\n",
      "Train loss: 0.0720894978054472\n",
      "Test loss: 0.4512111656367779\n",
      "\n",
      "Epoch 64\n",
      "---------\n",
      "Train loss: 0.06349129086309993\n",
      "Test loss: 0.6068482957780361\n",
      "\n",
      "Epoch 65\n",
      "---------\n",
      "Train loss: 0.06612367040125301\n",
      "Test loss: 0.7580982310076555\n",
      "\n",
      "Epoch 66\n",
      "---------\n",
      "Train loss: 0.07199845967399007\n",
      "Test loss: 0.4837833071748416\n",
      "\n",
      "Epoch 67\n",
      "---------\n",
      "Train loss: 0.06296628602855914\n",
      "Test loss: 0.41106359163920086\n",
      "\n",
      "Epoch 68\n",
      "---------\n",
      "Train loss: 0.06220371220764276\n",
      "Test loss: 0.691035178800424\n",
      "\n",
      "Epoch 69\n",
      "---------\n",
      "Train loss: 0.07134773056148677\n",
      "Test loss: 0.5278053705890974\n",
      "\n",
      "Epoch 70\n",
      "---------\n",
      "Train loss: 0.06619221826612547\n",
      "Test loss: 0.5060672828306755\n",
      "\n",
      "Epoch 71\n",
      "---------\n",
      "Train loss: 0.07039073628146907\n",
      "Test loss: 0.61370949447155\n",
      "\n",
      "Epoch 72\n",
      "---------\n",
      "Train loss: 0.07647318102897623\n",
      "Test loss: 0.44453720065454644\n",
      "\n",
      "Epoch 73\n",
      "---------\n",
      "Train loss: 0.06186097059902307\n",
      "Test loss: 0.521019900838534\n",
      "\n",
      "Epoch 74\n",
      "---------\n",
      "Train loss: 0.06501587797459718\n",
      "Test loss: 0.460267661139369\n",
      "\n",
      "Epoch 75\n",
      "---------\n",
      "Train loss: 0.06213170349144855\n",
      "Test loss: 0.43588303464154404\n",
      "\n",
      "Epoch 76\n",
      "---------\n",
      "Train loss: 0.06861163217675041\n",
      "Test loss: 0.5498877031107744\n",
      "\n",
      "Epoch 77\n",
      "---------\n",
      "Train loss: 0.06708226233997659\n",
      "Test loss: 0.5542126639435688\n",
      "\n",
      "Epoch 78\n",
      "---------\n",
      "Train loss: 0.07275009901590042\n",
      "Test loss: 0.4622019827365875\n",
      "\n",
      "Epoch 79\n",
      "---------\n",
      "Train loss: 0.060641530630606656\n",
      "Test loss: 0.4244837015867233\n",
      "\n",
      "Epoch 80\n",
      "---------\n",
      "Train loss: 0.05763980746269226\n",
      "Test loss: 0.5261423097302517\n",
      "\n",
      "Epoch 81\n",
      "---------\n",
      "Train loss: 0.05997946348066467\n",
      "Test loss: 0.39018642033139866\n",
      "\n",
      "Epoch 82\n",
      "---------\n",
      "Train loss: 0.06328985846374889\n",
      "Test loss: 0.4259754891196887\n",
      "\n",
      "Epoch 83\n",
      "---------\n",
      "Train loss: 0.0679060222983763\n",
      "Test loss: 0.3416869882494211\n",
      "\n",
      "Epoch 84\n",
      "---------\n",
      "Train loss: 0.0675147215433016\n",
      "Test loss: 0.5168443818887075\n",
      "\n",
      "Epoch 85\n",
      "---------\n",
      "Train loss: 0.06211464130870268\n",
      "Test loss: 0.5898768752813339\n",
      "\n",
      "Epoch 86\n",
      "---------\n",
      "Train loss: 0.06643524190184434\n",
      "Test loss: 0.5149435736238956\n",
      "\n",
      "Epoch 87\n",
      "---------\n",
      "Train loss: 0.06153537174435081\n",
      "Test loss: 0.377123959052066\n",
      "\n",
      "Epoch 88\n",
      "---------\n",
      "Train loss: 0.0630161774822989\n",
      "Test loss: 0.5047393664717674\n",
      "\n",
      "Epoch 89\n",
      "---------\n",
      "Train loss: 0.05934367789509329\n",
      "Test loss: 0.40372683852910995\n",
      "\n",
      "Epoch 90\n",
      "---------\n",
      "Train loss: 0.07017320040865122\n",
      "Test loss: 0.36943530493105453\n",
      "\n",
      "Epoch 91\n",
      "---------\n",
      "Train loss: 0.06609980144059739\n",
      "Test loss: 0.4035262080530326\n",
      "\n",
      "Epoch 92\n",
      "---------\n",
      "Train loss: 0.06384571026570189\n",
      "Test loss: 0.40083717554807663\n",
      "\n",
      "Epoch 93\n",
      "---------\n",
      "Train loss: 0.06203136935427382\n",
      "Test loss: 0.5540899193535248\n",
      "\n",
      "Epoch 94\n",
      "---------\n",
      "Train loss: 0.068859694390306\n",
      "Test loss: 0.6578071924547354\n",
      "\n",
      "Epoch 95\n",
      "---------\n",
      "Train loss: 0.07171311467332211\n",
      "Test loss: 0.5140168108046055\n",
      "\n",
      "Epoch 96\n",
      "---------\n",
      "Train loss: 0.06127721283937226\n",
      "Test loss: 0.3659276080628236\n",
      "\n",
      "Epoch 97\n",
      "---------\n",
      "Train loss: 0.0625376977353684\n",
      "Test loss: 0.4246323863044381\n",
      "\n",
      "Epoch 98\n",
      "---------\n",
      "Train loss: 0.05644121318048722\n",
      "Test loss: 0.45830944180488586\n",
      "\n",
      "Epoch 99\n",
      "---------\n",
      "Train loss: 0.05927274736412171\n",
      "Test loss: 0.513628205905358\n",
      "\n",
      "Epoch 100\n",
      "---------\n",
      "Train loss: 0.06075398829715276\n",
      "Test loss: 0.3684005963926514\n",
      "\n",
      "Epoch 101\n",
      "---------\n",
      "Train loss: 0.06102117825601552\n",
      "Test loss: 0.37558024128278095\n",
      "\n",
      "Epoch 102\n",
      "---------\n",
      "Train loss: 0.057234593898347404\n",
      "Test loss: 0.3740888486305873\n",
      "\n",
      "Epoch 103\n",
      "---------\n",
      "Train loss: 0.057413158906825086\n",
      "Test loss: 0.378425695002079\n",
      "\n",
      "Epoch 104\n",
      "---------\n",
      "Train loss: 0.058815703021733695\n",
      "Test loss: 0.3588079822560151\n",
      "\n",
      "Epoch 105\n",
      "---------\n",
      "Train loss: 0.06126303294346341\n",
      "Test loss: 0.3726242749641339\n",
      "\n",
      "Epoch 106\n",
      "---------\n",
      "Train loss: 0.057848390305062405\n",
      "Test loss: 0.5059917817513148\n",
      "\n",
      "Epoch 107\n",
      "---------\n",
      "Train loss: 0.057211128554332094\n",
      "Test loss: 0.4158715736120939\n",
      "\n",
      "Epoch 108\n",
      "---------\n",
      "Train loss: 0.05181723824274298\n",
      "Test loss: 0.46080952137708664\n",
      "\n",
      "Epoch 109\n",
      "---------\n",
      "Train loss: 0.06498839138579127\n",
      "Test loss: 0.4079795330762863\n",
      "\n",
      "Epoch 110\n",
      "---------\n",
      "Train loss: 0.05813979229109513\n",
      "Test loss: 0.3859196783353885\n",
      "\n",
      "Epoch 111\n",
      "---------\n",
      "Train loss: 0.060511710103349506\n",
      "Test loss: 0.35651083414753276\n",
      "\n",
      "Epoch 112\n",
      "---------\n",
      "Train loss: 0.05565692781709839\n",
      "Test loss: 0.4338433872908354\n",
      "\n",
      "Epoch 113\n",
      "---------\n",
      "Train loss: 0.055410290527081976\n",
      "Test loss: 0.3957850889613231\n",
      "\n",
      "Epoch 114\n",
      "---------\n",
      "Train loss: 0.0599036541597515\n",
      "Test loss: 0.5964334110418955\n",
      "\n",
      "Epoch 115\n",
      "---------\n",
      "Train loss: 0.06628970060547865\n",
      "Test loss: 0.38287222012877464\n",
      "\n",
      "Epoch 116\n",
      "---------\n",
      "Train loss: 0.053898466939761025\n",
      "Test loss: 0.376965028544267\n",
      "\n",
      "Epoch 117\n",
      "---------\n",
      "Train loss: 0.05405596856380234\n",
      "Test loss: 0.5213809460401535\n",
      "\n",
      "Epoch 118\n",
      "---------\n",
      "Train loss: 0.052770862270876566\n",
      "Test loss: 0.33781620177129906\n",
      "\n",
      "Epoch 119\n",
      "---------\n",
      "Train loss: 0.060293992616336896\n",
      "Test loss: 0.468953775241971\n",
      "\n",
      "Epoch 120\n",
      "---------\n",
      "Train loss: 0.06157951134986974\n",
      "Test loss: 0.38830901806553203\n",
      "\n",
      "Epoch 121\n",
      "---------\n",
      "Train loss: 0.05688008330321896\n",
      "Test loss: 0.4682336486876011\n",
      "\n",
      "Epoch 122\n",
      "---------\n",
      "Train loss: 0.0581169738131418\n",
      "Test loss: 0.4445079391201337\n",
      "\n",
      "Epoch 123\n",
      "---------\n",
      "Train loss: 0.052772419810345444\n",
      "Test loss: 0.4160943639775117\n",
      "\n",
      "Epoch 124\n",
      "---------\n",
      "Train loss: 0.055479115686958305\n",
      "Test loss: 0.36177236307412386\n",
      "\n",
      "Epoch 125\n",
      "---------\n",
      "Train loss: 0.05078570732242755\n",
      "Test loss: 0.4205484812458356\n",
      "\n",
      "Epoch 126\n",
      "---------\n",
      "Train loss: 0.05827674057611541\n",
      "Test loss: 0.4247727443774541\n",
      "\n",
      "Epoch 127\n",
      "---------\n",
      "Train loss: 0.05004706218008052\n",
      "Test loss: 0.4138265574971835\n",
      "\n",
      "Epoch 128\n",
      "---------\n",
      "Train loss: 0.05461058459508963\n",
      "Test loss: 0.38677408546209335\n",
      "\n",
      "Epoch 129\n",
      "---------\n",
      "Train loss: 0.04847057682864771\n",
      "Test loss: 0.4006728654106458\n",
      "\n",
      "Hidden SİZE XD 40\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            lead1  Model forecast\n",
      "Month                            \n",
      "1949-01-01  118.0      123.456642\n",
      "1949-02-01  132.0      129.292450\n",
      "1949-03-01  129.0      140.564178\n",
      "1949-04-01  121.0      132.863754\n",
      "1949-05-01  135.0      129.131927\n",
      "...           ...             ...\n",
      "1960-07-01  606.0      564.645020\n",
      "1960-08-01  508.0      532.439941\n",
      "1960-09-01  461.0      400.857788\n",
      "1960-10-01  390.0      404.948303\n",
      "1960-11-01  432.0      344.282410\n",
      "\n",
      "[144 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=lead1<br>Date=%{x}<br>Air Passengers=%{y}<extra></extra>",
         "legendgroup": "lead1",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "lead1",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "1949-01-01T00:00:00",
          "1949-02-01T00:00:00",
          "1949-03-01T00:00:00",
          "1949-04-01T00:00:00",
          "1949-05-01T00:00:00",
          "1949-06-01T00:00:00",
          "1949-07-01T00:00:00",
          "1949-08-01T00:00:00",
          "1949-09-01T00:00:00",
          "1949-10-01T00:00:00",
          "1949-11-01T00:00:00",
          "1949-12-01T00:00:00",
          "1950-01-01T00:00:00",
          "1950-02-01T00:00:00",
          "1950-03-01T00:00:00",
          "1950-04-01T00:00:00",
          "1950-05-01T00:00:00",
          "1950-06-01T00:00:00",
          "1950-07-01T00:00:00",
          "1950-08-01T00:00:00",
          "1950-09-01T00:00:00",
          "1950-10-01T00:00:00",
          "1950-11-01T00:00:00",
          "1950-12-01T00:00:00",
          "1951-01-01T00:00:00",
          "1951-02-01T00:00:00",
          "1951-03-01T00:00:00",
          "1951-04-01T00:00:00",
          "1951-05-01T00:00:00",
          "1951-06-01T00:00:00",
          "1951-07-01T00:00:00",
          "1951-08-01T00:00:00",
          "1951-09-01T00:00:00",
          "1951-10-01T00:00:00",
          "1951-11-01T00:00:00",
          "1951-12-01T00:00:00",
          "1952-01-01T00:00:00",
          "1952-02-01T00:00:00",
          "1952-03-01T00:00:00",
          "1952-04-01T00:00:00",
          "1952-05-01T00:00:00",
          "1952-06-01T00:00:00",
          "1952-07-01T00:00:00",
          "1952-08-01T00:00:00",
          "1952-09-01T00:00:00",
          "1952-10-01T00:00:00",
          "1952-11-01T00:00:00",
          "1952-12-01T00:00:00",
          "1953-01-01T00:00:00",
          "1953-02-01T00:00:00",
          "1953-03-01T00:00:00",
          "1953-04-01T00:00:00",
          "1953-05-01T00:00:00",
          "1953-06-01T00:00:00",
          "1953-07-01T00:00:00",
          "1953-08-01T00:00:00",
          "1953-09-01T00:00:00",
          "1953-10-01T00:00:00",
          "1953-11-01T00:00:00",
          "1953-12-01T00:00:00",
          "1954-01-01T00:00:00",
          "1954-02-01T00:00:00",
          "1954-03-01T00:00:00",
          "1954-04-01T00:00:00",
          "1954-05-01T00:00:00",
          "1954-06-01T00:00:00",
          "1954-07-01T00:00:00",
          "1954-08-01T00:00:00",
          "1954-09-01T00:00:00",
          "1954-10-01T00:00:00",
          "1954-11-01T00:00:00",
          "1954-12-01T00:00:00",
          "1955-01-01T00:00:00",
          "1955-02-01T00:00:00",
          "1955-03-01T00:00:00",
          "1955-04-01T00:00:00",
          "1955-05-01T00:00:00",
          "1955-06-01T00:00:00",
          "1955-07-01T00:00:00",
          "1955-08-01T00:00:00",
          "1955-09-01T00:00:00",
          "1955-10-01T00:00:00",
          "1955-11-01T00:00:00",
          "1955-12-01T00:00:00",
          "1956-01-01T00:00:00",
          "1956-02-01T00:00:00",
          "1956-03-01T00:00:00",
          "1956-04-01T00:00:00",
          "1956-05-01T00:00:00",
          "1956-06-01T00:00:00",
          "1956-07-01T00:00:00",
          "1956-08-01T00:00:00",
          "1956-09-01T00:00:00",
          "1956-10-01T00:00:00",
          "1956-11-01T00:00:00",
          "1956-12-01T00:00:00",
          "1957-01-01T00:00:00",
          "1957-02-01T00:00:00",
          "1957-03-01T00:00:00",
          "1957-04-01T00:00:00",
          "1957-05-01T00:00:00",
          "1957-06-01T00:00:00",
          "1957-07-01T00:00:00",
          "1957-08-01T00:00:00",
          "1957-09-01T00:00:00",
          "1957-10-01T00:00:00",
          "1957-11-01T00:00:00",
          "1957-12-01T00:00:00",
          "1958-01-01T00:00:00",
          "1958-01-01T00:00:00",
          "1958-02-01T00:00:00",
          "1958-03-01T00:00:00",
          "1958-04-01T00:00:00",
          "1958-05-01T00:00:00",
          "1958-06-01T00:00:00",
          "1958-07-01T00:00:00",
          "1958-08-01T00:00:00",
          "1958-09-01T00:00:00",
          "1958-10-01T00:00:00",
          "1958-11-01T00:00:00",
          "1958-12-01T00:00:00",
          "1959-01-01T00:00:00",
          "1959-02-01T00:00:00",
          "1959-03-01T00:00:00",
          "1959-04-01T00:00:00",
          "1959-05-01T00:00:00",
          "1959-06-01T00:00:00",
          "1959-07-01T00:00:00",
          "1959-08-01T00:00:00",
          "1959-09-01T00:00:00",
          "1959-10-01T00:00:00",
          "1959-11-01T00:00:00",
          "1959-12-01T00:00:00",
          "1960-01-01T00:00:00",
          "1960-02-01T00:00:00",
          "1960-03-01T00:00:00",
          "1960-04-01T00:00:00",
          "1960-05-01T00:00:00",
          "1960-06-01T00:00:00",
          "1960-07-01T00:00:00",
          "1960-08-01T00:00:00",
          "1960-09-01T00:00:00",
          "1960-10-01T00:00:00",
          "1960-11-01T00:00:00"
         ],
         "xaxis": "x",
         "y": [
          118,
          132,
          129,
          121,
          135,
          148,
          148,
          136,
          119,
          104,
          118,
          115,
          126,
          141,
          135,
          125,
          149,
          170,
          170,
          158,
          133,
          114,
          140,
          145,
          150,
          178,
          163,
          172,
          178,
          199,
          199,
          184,
          162,
          146,
          166,
          171,
          180,
          193,
          181,
          183,
          218,
          230,
          242,
          209,
          191,
          172,
          194,
          196,
          196,
          236,
          235,
          229,
          243,
          264,
          272,
          237,
          211,
          180,
          201,
          204,
          188,
          235,
          227,
          234,
          264,
          302,
          293,
          259,
          229,
          203,
          229,
          242,
          233,
          267,
          269,
          270,
          315,
          364,
          347,
          312,
          274,
          237,
          278,
          284,
          277,
          317,
          313,
          318,
          374,
          413,
          405,
          355,
          306,
          271,
          306,
          315,
          301,
          356,
          348,
          355,
          422,
          465,
          467,
          404,
          347,
          305,
          336,
          340,
          318,
          318,
          362,
          348,
          363,
          435,
          491,
          505,
          404,
          359,
          310,
          337,
          360,
          342,
          406,
          396,
          420,
          472,
          548,
          559,
          463,
          407,
          362,
          405,
          417,
          391,
          419,
          461,
          472,
          535,
          622,
          606,
          508,
          461,
          390,
          432
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=Model forecast<br>Date=%{x}<br>Air Passengers=%{y}<extra></extra>",
         "legendgroup": "Model forecast",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Model forecast",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "1949-01-01T00:00:00",
          "1949-02-01T00:00:00",
          "1949-03-01T00:00:00",
          "1949-04-01T00:00:00",
          "1949-05-01T00:00:00",
          "1949-06-01T00:00:00",
          "1949-07-01T00:00:00",
          "1949-08-01T00:00:00",
          "1949-09-01T00:00:00",
          "1949-10-01T00:00:00",
          "1949-11-01T00:00:00",
          "1949-12-01T00:00:00",
          "1950-01-01T00:00:00",
          "1950-02-01T00:00:00",
          "1950-03-01T00:00:00",
          "1950-04-01T00:00:00",
          "1950-05-01T00:00:00",
          "1950-06-01T00:00:00",
          "1950-07-01T00:00:00",
          "1950-08-01T00:00:00",
          "1950-09-01T00:00:00",
          "1950-10-01T00:00:00",
          "1950-11-01T00:00:00",
          "1950-12-01T00:00:00",
          "1951-01-01T00:00:00",
          "1951-02-01T00:00:00",
          "1951-03-01T00:00:00",
          "1951-04-01T00:00:00",
          "1951-05-01T00:00:00",
          "1951-06-01T00:00:00",
          "1951-07-01T00:00:00",
          "1951-08-01T00:00:00",
          "1951-09-01T00:00:00",
          "1951-10-01T00:00:00",
          "1951-11-01T00:00:00",
          "1951-12-01T00:00:00",
          "1952-01-01T00:00:00",
          "1952-02-01T00:00:00",
          "1952-03-01T00:00:00",
          "1952-04-01T00:00:00",
          "1952-05-01T00:00:00",
          "1952-06-01T00:00:00",
          "1952-07-01T00:00:00",
          "1952-08-01T00:00:00",
          "1952-09-01T00:00:00",
          "1952-10-01T00:00:00",
          "1952-11-01T00:00:00",
          "1952-12-01T00:00:00",
          "1953-01-01T00:00:00",
          "1953-02-01T00:00:00",
          "1953-03-01T00:00:00",
          "1953-04-01T00:00:00",
          "1953-05-01T00:00:00",
          "1953-06-01T00:00:00",
          "1953-07-01T00:00:00",
          "1953-08-01T00:00:00",
          "1953-09-01T00:00:00",
          "1953-10-01T00:00:00",
          "1953-11-01T00:00:00",
          "1953-12-01T00:00:00",
          "1954-01-01T00:00:00",
          "1954-02-01T00:00:00",
          "1954-03-01T00:00:00",
          "1954-04-01T00:00:00",
          "1954-05-01T00:00:00",
          "1954-06-01T00:00:00",
          "1954-07-01T00:00:00",
          "1954-08-01T00:00:00",
          "1954-09-01T00:00:00",
          "1954-10-01T00:00:00",
          "1954-11-01T00:00:00",
          "1954-12-01T00:00:00",
          "1955-01-01T00:00:00",
          "1955-02-01T00:00:00",
          "1955-03-01T00:00:00",
          "1955-04-01T00:00:00",
          "1955-05-01T00:00:00",
          "1955-06-01T00:00:00",
          "1955-07-01T00:00:00",
          "1955-08-01T00:00:00",
          "1955-09-01T00:00:00",
          "1955-10-01T00:00:00",
          "1955-11-01T00:00:00",
          "1955-12-01T00:00:00",
          "1956-01-01T00:00:00",
          "1956-02-01T00:00:00",
          "1956-03-01T00:00:00",
          "1956-04-01T00:00:00",
          "1956-05-01T00:00:00",
          "1956-06-01T00:00:00",
          "1956-07-01T00:00:00",
          "1956-08-01T00:00:00",
          "1956-09-01T00:00:00",
          "1956-10-01T00:00:00",
          "1956-11-01T00:00:00",
          "1956-12-01T00:00:00",
          "1957-01-01T00:00:00",
          "1957-02-01T00:00:00",
          "1957-03-01T00:00:00",
          "1957-04-01T00:00:00",
          "1957-05-01T00:00:00",
          "1957-06-01T00:00:00",
          "1957-07-01T00:00:00",
          "1957-08-01T00:00:00",
          "1957-09-01T00:00:00",
          "1957-10-01T00:00:00",
          "1957-11-01T00:00:00",
          "1957-12-01T00:00:00",
          "1958-01-01T00:00:00",
          "1958-01-01T00:00:00",
          "1958-02-01T00:00:00",
          "1958-03-01T00:00:00",
          "1958-04-01T00:00:00",
          "1958-05-01T00:00:00",
          "1958-06-01T00:00:00",
          "1958-07-01T00:00:00",
          "1958-08-01T00:00:00",
          "1958-09-01T00:00:00",
          "1958-10-01T00:00:00",
          "1958-11-01T00:00:00",
          "1958-12-01T00:00:00",
          "1959-01-01T00:00:00",
          "1959-02-01T00:00:00",
          "1959-03-01T00:00:00",
          "1959-04-01T00:00:00",
          "1959-05-01T00:00:00",
          "1959-06-01T00:00:00",
          "1959-07-01T00:00:00",
          "1959-08-01T00:00:00",
          "1959-09-01T00:00:00",
          "1959-10-01T00:00:00",
          "1959-11-01T00:00:00",
          "1959-12-01T00:00:00",
          "1960-01-01T00:00:00",
          "1960-02-01T00:00:00",
          "1960-03-01T00:00:00",
          "1960-04-01T00:00:00",
          "1960-05-01T00:00:00",
          "1960-06-01T00:00:00",
          "1960-07-01T00:00:00",
          "1960-08-01T00:00:00",
          "1960-09-01T00:00:00",
          "1960-10-01T00:00:00",
          "1960-11-01T00:00:00"
         ],
         "xaxis": "x",
         "y": [
          123.4566421508789,
          129.29244995117188,
          140.56417846679688,
          132.86375427246094,
          129.13192749023438,
          145.74472045898438,
          151.83474731445312,
          149.85733032226562,
          140.276123046875,
          128.22848510742188,
          118.33027648925781,
          134.330322265625,
          122.06766510009766,
          137.10862731933594,
          146.95465087890625,
          137.03506469726562,
          132.65673828125,
          158.8373565673828,
          170.8944854736328,
          169.79159545898438,
          161.98333740234375,
          140.31106567382812,
          127.57127380371094,
          153.8744659423828,
          145.6768341064453,
          154.0135498046875,
          181.1566925048828,
          160.29588317871094,
          180.32479858398438,
          180.68896484375,
          201.92330932617188,
          201.30078125,
          192.9094696044922,
          173.50413513183594,
          156.76820373535156,
          174.2092742919922,
          171.29092407226562,
          183.58494567871094,
          196.09628295898438,
          183.98085021972656,
          192.58953857421875,
          218.60763549804688,
          232.17955017089844,
          257.43115234375,
          201.22952270507812,
          207.49383544921875,
          186.3359375,
          202.33709716796875,
          197.45957946777344,
          203.7086181640625,
          235.73069763183594,
          241.6475830078125,
          241.668701171875,
          262.770751953125,
          278.4776306152344,
          262.4186706542969,
          226.28314208984375,
          204.43861389160156,
          199.9385223388672,
          213.27957153320312,
          206.67257690429688,
          196.85009765625,
          234.07183837890625,
          229.69850158691406,
          254.1695098876953,
          280.0132751464844,
          305.1859130859375,
          261.3282165527344,
          265.3204040527344,
          223.93125915527344,
          203.6916046142578,
          241.96055603027344,
          251.7454833984375,
          237.77755737304688,
          283.3914489746094,
          263.6735534667969,
          295.81121826171875,
          338.02569580078125,
          348.3334045410156,
          317.56610107421875,
          296.65423583984375,
          277.0147399902344,
          233.79852294921875,
          269.00457763671875,
          271.44268798828125,
          305.2221984863281,
          328.14013671875,
          292.64794921875,
          363.5008544921875,
          416.69921875,
          417.1184997558594,
          365.5416259765625,
          300.31549072265625,
          277.665283203125,
          277.974365234375,
          304.0691223144531,
          303.24224853515625,
          332.72271728515625,
          361.8431396484375,
          322.9369201660156,
          401.81256103515625,
          470.46636962890625,
          461.6751708984375,
          410.43865966796875,
          349.456787109375,
          299.6743469238281,
          303.22320556640625,
          348.65240478515625,
          354.196044921875,
          382.60150146484375,
          327.81658935546875,
          389.05133056640625,
          323.3351135253906,
          419.5389709472656,
          476.22406005859375,
          489.40655517578125,
          444.80413818359375,
          340.205810546875,
          337.1828918457031,
          272.6742248535156,
          353.659912109375,
          392.51373291015625,
          320.79876708984375,
          463.57940673828125,
          361.662353515625,
          418.133056640625,
          469.73675537109375,
          528.1978149414062,
          495.7935791015625,
          376.8436279296875,
          368.1498718261719,
          319.79345703125,
          474.888427734375,
          394.6971435546875,
          343.9627990722656,
          437.0445556640625,
          451.98004150390625,
          420.75555419921875,
          516.4488525390625,
          564.64501953125,
          532.43994140625,
          400.8577880859375,
          404.94830322265625,
          344.28240966796875
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "Test set start",
          "x": 0.75,
          "xref": "paper",
          "y": 0.8,
          "yref": "paper"
         }
        ],
        "legend": {
         "orientation": "h",
         "title": {
          "text": ""
         },
         "tracegroupgap": 0,
         "y": 1.02
        },
        "margin": {
         "t": 60
        },
        "shapes": [
         {
          "line": {
           "dash": "dash",
           "width": 4
          },
          "type": "line",
          "x0": "1958-01-01",
          "x1": "1958-01-01",
          "xref": "x",
          "y0": 0,
          "y1": 1,
          "yref": "y domain"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "font": {
           "size": 18
          },
          "xaxis": {
           "title": {
            "font": {
             "size": 24
            }
           }
          },
          "yaxis": {
           "title": {
            "font": {
             "size": 24
            }
           }
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Date"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Air Passengers"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Store losses per epoch\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "print(\"Untrained test\\n--------\")\n",
    "initial_test_loss = test_model(test_loader, model, loss_function)\n",
    "test_losses.append(initial_test_loss)\n",
    "print()\n",
    "\n",
    "\n",
    "for ix_epoch in range(130):\n",
    "    print(f\"Epoch {ix_epoch}\\n---------\")\n",
    "    train_loss = train_model(train_loader, model, loss_function, optimizer=optimizer)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    test_loss = test_model(test_loader, model, loss_function)\n",
    "    test_losses.append(test_loss)\n",
    "    print()\n",
    "\n",
    "print(\"Hidden SİZE XD\", model.hidden_size)\n",
    "\n",
    "# Plot loss per epoch\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Testing loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# # Evaluation\n",
    "\n",
    "# %%\n",
    "def predict(data_loader, model):\n",
    "    \"\"\"Just like `test_loop` function but keep track of the outputs instead of the loss\n",
    "    function.\n",
    "    \"\"\"\n",
    "    output = torch.tensor([])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, _ in data_loader:\n",
    "            y_star = model(X)\n",
    "            output = torch.cat((output, y_star), 0)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# %%\n",
    "train_eval_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "ystar_col = \"Model forecast\"\n",
    "df_train[ystar_col] = predict(train_eval_loader, model).numpy()\n",
    "df_test[ystar_col] = predict(test_loader, model).numpy()\n",
    "\n",
    "df_out = pd.concat((df_train, df_test))[[target, ystar_col]]\n",
    "\n",
    "for c in df_out.columns:\n",
    "    df_out[c] = df_out[c] * target_stdev + target_mean\n",
    "\n",
    "print(df_out)\n",
    "\n",
    "# %%\n",
    "fig = px.line(df_out, labels={'value': \"Air Passengers\", 'Month': 'Date'})\n",
    "fig.add_vline(x=test_start, line_width=4, line_dash=\"dash\")\n",
    "fig.add_annotation(xref=\"paper\", x=0.75, yref=\"paper\", y=0.8, text=\"Test set start\", showarrow=False)\n",
    "fig.update_layout(\n",
    "  template=plot_template, legend=dict(orientation='h', y=1.02, title_text=\"\")\n",
    ")\n",
    "fig.show()\n",
    "# fig.write_image(\"air_passengers_forecast.png\", width=1200, height=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE 0.07784964714789822\n",
      "Test MAPE 0.11310766137940302\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "mape = mean_absolute_percentage_error(df_out['Model forecast'], df_out['lead1'])\n",
    "mape_test = mean_absolute_percentage_error(df_out['lead1'].iloc[118:144], df_out['Model forecast'].iloc[118:144])\n",
    "print(\"MAPE\", mape)\n",
    "print(\"Test MAPE\", mape_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.11.2)",
   "language": "python",
   "name": "3.11.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
