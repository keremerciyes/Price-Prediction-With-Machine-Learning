{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=Passengers<br>Month=%{x}<br>Passengers=%{y}<extra></extra>",
         "legendgroup": "Passengers",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Passengers",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "1949-01-01T00:00:00",
          "1949-02-01T00:00:00",
          "1949-03-01T00:00:00",
          "1949-04-01T00:00:00",
          "1949-05-01T00:00:00",
          "1949-06-01T00:00:00",
          "1949-07-01T00:00:00",
          "1949-08-01T00:00:00",
          "1949-09-01T00:00:00",
          "1949-10-01T00:00:00",
          "1949-11-01T00:00:00",
          "1949-12-01T00:00:00",
          "1950-01-01T00:00:00",
          "1950-02-01T00:00:00",
          "1950-03-01T00:00:00",
          "1950-04-01T00:00:00",
          "1950-05-01T00:00:00",
          "1950-06-01T00:00:00",
          "1950-07-01T00:00:00",
          "1950-08-01T00:00:00",
          "1950-09-01T00:00:00",
          "1950-10-01T00:00:00",
          "1950-11-01T00:00:00",
          "1950-12-01T00:00:00",
          "1951-01-01T00:00:00",
          "1951-02-01T00:00:00",
          "1951-03-01T00:00:00",
          "1951-04-01T00:00:00",
          "1951-05-01T00:00:00",
          "1951-06-01T00:00:00",
          "1951-07-01T00:00:00",
          "1951-08-01T00:00:00",
          "1951-09-01T00:00:00",
          "1951-10-01T00:00:00",
          "1951-11-01T00:00:00",
          "1951-12-01T00:00:00",
          "1952-01-01T00:00:00",
          "1952-02-01T00:00:00",
          "1952-03-01T00:00:00",
          "1952-04-01T00:00:00",
          "1952-05-01T00:00:00",
          "1952-06-01T00:00:00",
          "1952-07-01T00:00:00",
          "1952-08-01T00:00:00",
          "1952-09-01T00:00:00",
          "1952-10-01T00:00:00",
          "1952-11-01T00:00:00",
          "1952-12-01T00:00:00",
          "1953-01-01T00:00:00",
          "1953-02-01T00:00:00",
          "1953-03-01T00:00:00",
          "1953-04-01T00:00:00",
          "1953-05-01T00:00:00",
          "1953-06-01T00:00:00",
          "1953-07-01T00:00:00",
          "1953-08-01T00:00:00",
          "1953-09-01T00:00:00",
          "1953-10-01T00:00:00",
          "1953-11-01T00:00:00",
          "1953-12-01T00:00:00",
          "1954-01-01T00:00:00",
          "1954-02-01T00:00:00",
          "1954-03-01T00:00:00",
          "1954-04-01T00:00:00",
          "1954-05-01T00:00:00",
          "1954-06-01T00:00:00",
          "1954-07-01T00:00:00",
          "1954-08-01T00:00:00",
          "1954-09-01T00:00:00",
          "1954-10-01T00:00:00",
          "1954-11-01T00:00:00",
          "1954-12-01T00:00:00",
          "1955-01-01T00:00:00",
          "1955-02-01T00:00:00",
          "1955-03-01T00:00:00",
          "1955-04-01T00:00:00",
          "1955-05-01T00:00:00",
          "1955-06-01T00:00:00",
          "1955-07-01T00:00:00",
          "1955-08-01T00:00:00",
          "1955-09-01T00:00:00",
          "1955-10-01T00:00:00",
          "1955-11-01T00:00:00",
          "1955-12-01T00:00:00",
          "1956-01-01T00:00:00",
          "1956-02-01T00:00:00",
          "1956-03-01T00:00:00",
          "1956-04-01T00:00:00",
          "1956-05-01T00:00:00",
          "1956-06-01T00:00:00",
          "1956-07-01T00:00:00",
          "1956-08-01T00:00:00",
          "1956-09-01T00:00:00",
          "1956-10-01T00:00:00",
          "1956-11-01T00:00:00",
          "1956-12-01T00:00:00",
          "1957-01-01T00:00:00",
          "1957-02-01T00:00:00",
          "1957-03-01T00:00:00",
          "1957-04-01T00:00:00",
          "1957-05-01T00:00:00",
          "1957-06-01T00:00:00",
          "1957-07-01T00:00:00",
          "1957-08-01T00:00:00",
          "1957-09-01T00:00:00",
          "1957-10-01T00:00:00",
          "1957-11-01T00:00:00",
          "1957-12-01T00:00:00",
          "1958-01-01T00:00:00",
          "1958-02-01T00:00:00",
          "1958-03-01T00:00:00",
          "1958-04-01T00:00:00",
          "1958-05-01T00:00:00",
          "1958-06-01T00:00:00",
          "1958-07-01T00:00:00",
          "1958-08-01T00:00:00",
          "1958-09-01T00:00:00",
          "1958-10-01T00:00:00",
          "1958-11-01T00:00:00",
          "1958-12-01T00:00:00",
          "1959-01-01T00:00:00",
          "1959-02-01T00:00:00",
          "1959-03-01T00:00:00",
          "1959-04-01T00:00:00",
          "1959-05-01T00:00:00",
          "1959-06-01T00:00:00",
          "1959-07-01T00:00:00",
          "1959-08-01T00:00:00",
          "1959-09-01T00:00:00",
          "1959-10-01T00:00:00",
          "1959-11-01T00:00:00",
          "1959-12-01T00:00:00",
          "1960-01-01T00:00:00",
          "1960-02-01T00:00:00",
          "1960-03-01T00:00:00",
          "1960-04-01T00:00:00",
          "1960-05-01T00:00:00",
          "1960-06-01T00:00:00",
          "1960-07-01T00:00:00",
          "1960-08-01T00:00:00",
          "1960-09-01T00:00:00",
          "1960-10-01T00:00:00",
          "1960-11-01T00:00:00",
          "1960-12-01T00:00:00"
         ],
         "xaxis": "x",
         "y": [
          112,
          118,
          132,
          129,
          121,
          135,
          148,
          148,
          136,
          119,
          104,
          118,
          115,
          126,
          141,
          135,
          125,
          149,
          170,
          170,
          158,
          133,
          114,
          140,
          145,
          150,
          178,
          163,
          172,
          178,
          199,
          199,
          184,
          162,
          146,
          166,
          171,
          180,
          193,
          181,
          183,
          218,
          230,
          242,
          209,
          191,
          172,
          194,
          196,
          196,
          236,
          235,
          229,
          243,
          264,
          272,
          237,
          211,
          180,
          201,
          204,
          188,
          235,
          227,
          234,
          264,
          302,
          293,
          259,
          229,
          203,
          229,
          242,
          233,
          267,
          269,
          270,
          315,
          364,
          347,
          312,
          274,
          237,
          278,
          284,
          277,
          317,
          313,
          318,
          374,
          413,
          405,
          355,
          306,
          271,
          306,
          315,
          301,
          356,
          348,
          355,
          422,
          465,
          467,
          404,
          347,
          305,
          336,
          340,
          318,
          362,
          348,
          363,
          435,
          491,
          505,
          404,
          359,
          310,
          337,
          360,
          342,
          406,
          396,
          420,
          472,
          548,
          559,
          463,
          407,
          362,
          405,
          417,
          391,
          419,
          461,
          472,
          535,
          622,
          606,
          508,
          461,
          390,
          432
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "orientation": "h",
         "title": {
          "text": ""
         },
         "tracegroupgap": 0,
         "y": 1.02
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "font": {
           "size": 18
          },
          "xaxis": {
           "title": {
            "font": {
             "size": 24
            }
           }
          },
          "yaxis": {
           "title": {
            "font": {
             "size": 24
            }
           }
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Month"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Passengers"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set fraction: 0.24475524475524477\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # How to use PyTorch LSTMs for time series regression\n",
    "\n",
    "# %% [markdown]\n",
    "# # Data\n",
    "\n",
    "# %% [markdown]\n",
    "# 1. Download the Air Passengers data.\n",
    "# 2. Load the Air Passengers data into a DataFrame.\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data-sets/BTC-USD-2018-2023.csv\", index_col=\"Date\", parse_dates=True)\n",
    "df.rename(columns={'#Passengers': ''}, inplace=True)\n",
    "\n",
    "# %%\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "plot_template = dict(\n",
    "    layout=go.Layout({\n",
    "        \"font_size\": 18,\n",
    "        \"xaxis_title_font_size\": 24,\n",
    "        \"yaxis_title_font_size\": 24})\n",
    ")\n",
    "\n",
    "fig = px.line(df, labels=dict(index=\"Date\", value=\"Passengers\"))\n",
    "fig.update_layout(\n",
    "  template=plot_template, legend=dict(orientation='h', y=1.02, title_text=\"\")\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Create the target variable\n",
    "\n",
    "# %%\n",
    "forecast_lead = 1\n",
    "target = f\"lead{forecast_lead}\"\n",
    "\n",
    "df[target] = df[\"Passengers\"].shift(-forecast_lead)\n",
    "df = df.iloc[:-forecast_lead]\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Create a hold-out test set and preprocess the data\n",
    "\n",
    "# %%\n",
    "test_start = \"1958-01-01\"\n",
    "\n",
    "df_train = df.loc[:test_start].copy()\n",
    "df_test = df.loc[test_start:].copy()\n",
    "\n",
    "print(\"Test set fraction:\", len(df_test) / len(df))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Standardize the features and target, based on the training set\n",
    "\n",
    "# %%\n",
    "target_mean = df_train[target].mean()\n",
    "target_stdev = df_train[target].std()\n",
    "\n",
    "df_train[\"Passengers\"] = (df_train[\"Passengers\"] - target_mean) / target_stdev\n",
    "df_test[\"Passengers\"] = (df_test[\"Passengers\"] - target_mean) / target_stdev\n",
    "\n",
    "df_train[target] = (df_train[target] - target_mean) / target_stdev\n",
    "df_test[target] = (df_test[target] - target_mean) / target_stdev\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Create datasets that PyTorch `DataLoader` can work with\n",
    "\n",
    "# %%\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, dataframe, target, sequence_length=5):\n",
    "        self.target = target\n",
    "        self.sequence_length = sequence_length\n",
    "        self.y = torch.tensor(dataframe[self.target].values).float()\n",
    "        self.X = torch.tensor(dataframe['Passengers'].values).float().unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, i): \n",
    "        if i >= self.sequence_length - 1:\n",
    "            i_start = i - self.sequence_length + 1\n",
    "            x = self.X[i_start:(i + 1), :]\n",
    "        else:\n",
    "            padding = self.X[0].repeat(self.sequence_length - i - 1, 1)\n",
    "            x = self.X[0:(i + 1), :]\n",
    "            x = torch.cat((padding, x), 0)\n",
    "\n",
    "        return x, self.y[i]\n",
    "        \n",
    "# Continue the rest of the code as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: torch.Size([3, 3, 1])\n",
      "Target shape: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Create the datasets and data loaders\n",
    "\n",
    "# %%\n",
    "from bayes_opt import BayesianOptimization, UtilityFunction\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(101)\n",
    "\n",
    "batch_size = 3\n",
    "sequence_length = 3\n",
    "\n",
    "train_dataset = SequenceDataset(\n",
    "    df_train,\n",
    "    target=target,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "test_dataset = SequenceDataset(\n",
    "    df_test,\n",
    "    target=target,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "X, y = next(iter(train_loader))\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "\n",
    "# %% [markdown]\n",
    "# # The model and learning algorithm\n",
    "\n",
    "# %%\n",
    "from torch import nn\n",
    "\n",
    "class ShallowRegressionLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=1,\n",
    "            hidden_size=hidden_size,\n",
    "            batch_first=True,\n",
    "            num_layers=self.num_layers\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(in_features=self.hidden_size, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).requires_grad_()\n",
    "        \n",
    "        _, (hn, _) = self.lstm(x, (h0, c0))\n",
    "        out = self.linear(hn[0]).flatten()\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | batch_... | learni... | num_hi... | num_la... | weight... |\n",
      "-------------------------------------------------------------------------------------\n",
      "Train loss: 0.9599555233443106\n",
      "Test loss: 5.4819841384887695\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-5.482   \u001b[0m | \u001b[0m46.04    \u001b[0m | \u001b[0m-2.839   \u001b[0m | \u001b[0m1.007    \u001b[0m | \u001b[0m2.605    \u001b[0m | \u001b[0m-4.56    \u001b[0m |\n",
      "Train loss: 0.8940688709954958\n",
      "Test loss: 5.955228805541992\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m-5.955   \u001b[0m | \u001b[0m10.97    \u001b[0m | \u001b[0m-4.441   \u001b[0m | \u001b[0m22.77    \u001b[0m | \u001b[0m2.794    \u001b[0m | \u001b[0m-3.384   \u001b[0m |\n",
      "Train loss: 1.0792231813475892\n",
      "Test loss: 6.152967631816864\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-6.153   \u001b[0m | \u001b[0m46.27    \u001b[0m | \u001b[0m-2.944   \u001b[0m | \u001b[0m13.88    \u001b[0m | \u001b[0m3.756    \u001b[0m | \u001b[0m-4.918   \u001b[0m |\n",
      "Train loss: 1.1144888835984308\n",
      "Test loss: 6.4306001762549085\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-6.431   \u001b[0m | \u001b[0m73.41    \u001b[0m | \u001b[0m-3.748   \u001b[0m | \u001b[0m36.2     \u001b[0m | \u001b[0m2.281    \u001b[0m | \u001b[0m-4.406   \u001b[0m |\n",
      "Train loss: 0.5662313249289386\n",
      "Test loss: 1.4251145394518971\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m-1.425   \u001b[0m | \u001b[95m87.48    \u001b[0m | \u001b[95m-2.095   \u001b[0m | \u001b[95m20.75    \u001b[0m | \u001b[95m3.385    \u001b[0m | \u001b[95m-2.371   \u001b[0m |\n",
      "Train loss: 0.5154625125531409\n",
      "Test loss: 0.9882196436325709\n",
      "| \u001b[95m6        \u001b[0m | \u001b[95m-0.9882  \u001b[0m | \u001b[95m87.81    \u001b[0m | \u001b[95m-2.086   \u001b[0m | \u001b[95m21.5     \u001b[0m | \u001b[95m3.312    \u001b[0m | \u001b[95m-2.124   \u001b[0m |\n",
      "Train loss: 0.44027509344615845\n",
      "Test loss: 1.5825480502098799\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-1.583   \u001b[0m | \u001b[0m93.39    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m24.21    \u001b[0m | \u001b[0m2.971    \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 1.0910975679352477\n",
      "Test loss: 6.05984150369962\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-6.06    \u001b[0m | \u001b[0m87.12    \u001b[0m | \u001b[0m-4.713   \u001b[0m | \u001b[0m28.41    \u001b[0m | \u001b[0m2.74     \u001b[0m | \u001b[0m-2.342   \u001b[0m |\n",
      "Train loss: 0.3935422425133151\n",
      "Test loss: 0.9208150313546261\n",
      "| \u001b[95m9        \u001b[0m | \u001b[95m-0.9208  \u001b[0m | \u001b[95m91.93    \u001b[0m | \u001b[95m-2.0     \u001b[0m | \u001b[95m19.84    \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m-2.0     \u001b[0m |\n",
      "Train loss: 0.4976651999052748\n",
      "Test loss: 1.462478316699465\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-1.462   \u001b[0m | \u001b[0m98.64    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m18.67    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.5527316839056643\n",
      "Test loss: 1.727020399024089\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-1.727   \u001b[0m | \u001b[0m96.53    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m11.26    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 1.04126889198213\n",
      "Test loss: 6.26565957069397\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-6.266   \u001b[0m | \u001b[0m104.0    \u001b[0m | \u001b[0m-5.0     \u001b[0m | \u001b[0m13.36    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 1.0462077634560096\n",
      "Test loss: 5.379275759061177\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-5.379   \u001b[0m | \u001b[0m94.01    \u001b[0m | \u001b[0m-5.0     \u001b[0m | \u001b[0m19.29    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 0.30450186824954645\n",
      "Test loss: 0.7664406380305687\n",
      "| \u001b[95m14       \u001b[0m | \u001b[95m-0.7664  \u001b[0m | \u001b[95m99.06    \u001b[0m | \u001b[95m-2.0     \u001b[0m | \u001b[95m23.27    \u001b[0m | \u001b[95m2.0      \u001b[0m | \u001b[95m-2.0     \u001b[0m |\n",
      "Train loss: 0.4173297014817394\n",
      "Test loss: 1.4119221791625023\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-1.412   \u001b[0m | \u001b[0m103.9    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m24.73    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.3692390312994453\n",
      "Test loss: 1.2569017612064879\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m-1.257   \u001b[0m | \u001b[0m100.5    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m29.93    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.40645710922576284\n",
      "Test loss: 1.5410199450949829\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m-1.541   \u001b[0m | \u001b[0m107.9    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m32.07    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.36136643228599347\n",
      "Test loss: 1.7578238832453887\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m-1.758   \u001b[0m | \u001b[0m103.1    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m37.56    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 0.874792617418476\n",
      "Test loss: 3.9655307133992515\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m-3.966   \u001b[0m | \u001b[0m90.66    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m4.908    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.9859173882098214\n",
      "Test loss: 6.598897010087967\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m-6.599   \u001b[0m | \u001b[0m109.0    \u001b[0m | \u001b[0m-5.0     \u001b[0m | \u001b[0m39.97    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.4035207811944388\n",
      "Test loss: 2.3096331357955933\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m-2.31    \u001b[0m | \u001b[0m104.7    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m29.12    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 0.31420613775923345\n",
      "Test loss: 0.9218213018029928\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m-0.9218  \u001b[0m | \u001b[0m96.85    \u001b[0m | \u001b[0m-2.006   \u001b[0m | \u001b[0m36.32    \u001b[0m | \u001b[0m3.009    \u001b[0m | \u001b[0m-2.749   \u001b[0m |\n",
      "Train loss: 0.4181011346345012\n",
      "Test loss: 1.2285144409785669\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m-1.229   \u001b[0m | \u001b[0m96.41    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m42.19    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 1.0254831692656956\n",
      "Test loss: 5.813218394915263\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m-5.813   \u001b[0m | \u001b[0m91.04    \u001b[0m | \u001b[0m-4.643   \u001b[0m | \u001b[0m43.69    \u001b[0m | \u001b[0m3.746    \u001b[0m | \u001b[0m-2.074   \u001b[0m |\n",
      "Train loss: 1.0493011563210874\n",
      "Test loss: 5.646604339281718\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m-5.647   \u001b[0m | \u001b[0m99.2     \u001b[0m | \u001b[0m-4.274   \u001b[0m | \u001b[0m35.12    \u001b[0m | \u001b[0m3.973    \u001b[0m | \u001b[0m-4.63    \u001b[0m |\n",
      "Train loss: 1.069360132757071\n",
      "Test loss: 7.069298575321834\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m-7.069   \u001b[0m | \u001b[0m100.3    \u001b[0m | \u001b[0m-3.71    \u001b[0m | \u001b[0m26.65    \u001b[0m | \u001b[0m2.648    \u001b[0m | \u001b[0m-2.616   \u001b[0m |\n",
      "Train loss: 0.41406491420206587\n",
      "Test loss: 1.6654815419266622\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m-1.665   \u001b[0m | \u001b[0m89.95    \u001b[0m | \u001b[0m-2.021   \u001b[0m | \u001b[0m20.73    \u001b[0m | \u001b[0m2.66     \u001b[0m | \u001b[0m-2.059   \u001b[0m |\n",
      "Train loss: 0.2955898341999666\n",
      "Test loss: 1.785257063806057\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m-1.785   \u001b[0m | \u001b[0m96.46    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m38.63    \u001b[0m | \u001b[0m3.244    \u001b[0m | \u001b[0m-3.34    \u001b[0m |\n",
      "Train loss: 0.6448414034235317\n",
      "Test loss: 1.393202317878604\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m-1.393   \u001b[0m | \u001b[0m96.1     \u001b[0m | \u001b[0m-2.245   \u001b[0m | \u001b[0m20.96    \u001b[0m | \u001b[0m2.683    \u001b[0m | \u001b[0m-2.113   \u001b[0m |\n",
      "Train loss: 0.9748272913432604\n",
      "Test loss: 6.840171843767166\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m-6.84    \u001b[0m | \u001b[0m98.65    \u001b[0m | \u001b[0m-3.583   \u001b[0m | \u001b[0m21.09    \u001b[0m | \u001b[0m2.629    \u001b[0m | \u001b[0m-3.03    \u001b[0m |\n",
      "Train loss: 0.8772671027360736\n",
      "Test loss: 4.718003431955974\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m-4.718   \u001b[0m | \u001b[0m96.43    \u001b[0m | \u001b[0m-2.972   \u001b[0m | \u001b[0m36.87    \u001b[0m | \u001b[0m2.026    \u001b[0m | \u001b[0m-3.471   \u001b[0m |\n",
      "Train loss: 0.6471767316798906\n",
      "Test loss: 1.730307433133324\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m-1.73    \u001b[0m | \u001b[0m91.38    \u001b[0m | \u001b[0m-2.277   \u001b[0m | \u001b[0m20.77    \u001b[0m | \u001b[0m2.834    \u001b[0m | \u001b[0m-2.608   \u001b[0m |\n",
      "Train loss: 0.40217212114382433\n",
      "Test loss: 0.948214752599597\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m-0.9482  \u001b[0m | \u001b[0m96.87    \u001b[0m | \u001b[0m-2.222   \u001b[0m | \u001b[0m37.46    \u001b[0m | \u001b[0m3.35     \u001b[0m | \u001b[0m-2.105   \u001b[0m |\n",
      "Train loss: 0.4484539169415429\n",
      "Test loss: 1.766199649622043\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m-1.766   \u001b[0m | \u001b[0m93.79    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m21.3     \u001b[0m | \u001b[0m2.251    \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.3972145523120825\n",
      "Test loss: 1.5622006605068843\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m-1.562   \u001b[0m | \u001b[0m98.11    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m36.22    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.3292213626751815\n",
      "Test loss: 1.5804276230434577\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m-1.58    \u001b[0m | \u001b[0m97.54    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m41.06    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-3.146   \u001b[0m |\n",
      "Train loss: 0.39403084879489364\n",
      "Test loss: 1.2997056214759748\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m-1.3     \u001b[0m | \u001b[0m96.54    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m23.64    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.3490966638373966\n",
      "Test loss: 1.5336006507277489\n",
      "| \u001b[0m38       \u001b[0m | \u001b[0m-1.534   \u001b[0m | \u001b[0m102.8    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m31.27    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.41895430863558036\n",
      "Test loss: 3.052806278069814\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m-3.053   \u001b[0m | \u001b[0m98.7     \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m42.55    \u001b[0m | \u001b[0m2.549    \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 0.5285241294847298\n",
      "Test loss: 1.2101154513657093\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m-1.21    \u001b[0m | \u001b[0m104.9    \u001b[0m | \u001b[0m-2.273   \u001b[0m | \u001b[0m32.68    \u001b[0m | \u001b[0m3.27     \u001b[0m | \u001b[0m-2.872   \u001b[0m |\n",
      "Train loss: 0.3314907326790932\n",
      "Test loss: 0.6402578620860974\n",
      "| \u001b[95m41       \u001b[0m | \u001b[95m-0.6403  \u001b[0m | \u001b[95m105.8    \u001b[0m | \u001b[95m-2.0     \u001b[0m | \u001b[95m30.17    \u001b[0m | \u001b[95m3.419    \u001b[0m | \u001b[95m-2.0     \u001b[0m |\n",
      "Train loss: 0.9761721085052233\n",
      "Test loss: 5.319219917058945\n",
      "| \u001b[0m42       \u001b[0m | \u001b[0m-5.319   \u001b[0m | \u001b[0m105.8    \u001b[0m | \u001b[0m-4.129   \u001b[0m | \u001b[0m30.94    \u001b[0m | \u001b[0m2.222    \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.3675109502934926\n",
      "Test loss: 0.9981887570271889\n",
      "| \u001b[0m43       \u001b[0m | \u001b[0m-0.9982  \u001b[0m | \u001b[0m107.3    \u001b[0m | \u001b[0m-2.156   \u001b[0m | \u001b[0m33.88    \u001b[0m | \u001b[0m3.555    \u001b[0m | \u001b[0m-4.256   \u001b[0m |\n",
      "Train loss: 0.3895867004034084\n",
      "Test loss: 1.4504592586308718\n",
      "| \u001b[0m44       \u001b[0m | \u001b[0m-1.45    \u001b[0m | \u001b[0m105.1    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m35.19    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-3.891   \u001b[0m |\n",
      "Train loss: 0.42145762871950865\n",
      "Test loss: 0.8625401183962822\n",
      "| \u001b[0m45       \u001b[0m | \u001b[0m-0.8625  \u001b[0m | \u001b[0m106.8    \u001b[0m | \u001b[0m-2.089   \u001b[0m | \u001b[0m31.61    \u001b[0m | \u001b[0m2.988    \u001b[0m | \u001b[0m-4.795   \u001b[0m |\n",
      "Train loss: 0.5849986961363135\n",
      "Test loss: 2.335518861810366\n",
      "| \u001b[0m46       \u001b[0m | \u001b[0m-2.336   \u001b[0m | \u001b[0m106.9    \u001b[0m | \u001b[0m-2.329   \u001b[0m | \u001b[0m26.24    \u001b[0m | \u001b[0m3.178    \u001b[0m | \u001b[0m-2.229   \u001b[0m |\n",
      "Train loss: 0.37954307850953695\n",
      "Test loss: 1.417633621642987\n",
      "| \u001b[0m47       \u001b[0m | \u001b[0m-1.418   \u001b[0m | \u001b[0m103.4    \u001b[0m | \u001b[0m-2.075   \u001b[0m | \u001b[0m29.31    \u001b[0m | \u001b[0m3.912    \u001b[0m | \u001b[0m-2.678   \u001b[0m |\n",
      "Train loss: 0.3751512236540785\n",
      "Test loss: 2.038246234258016\n",
      "| \u001b[0m48       \u001b[0m | \u001b[0m-2.038   \u001b[0m | \u001b[0m108.2    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m30.42    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-3.198   \u001b[0m |\n",
      "Train loss: 0.43239159121908044\n",
      "Test loss: 1.30321413744241\n",
      "| \u001b[0m49       \u001b[0m | \u001b[0m-1.303   \u001b[0m | \u001b[0m88.18    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m22.86    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-4.418   \u001b[0m |\n",
      "Train loss: 0.595462025571111\n",
      "Test loss: 1.7199589163064957\n",
      "| \u001b[0m50       \u001b[0m | \u001b[0m-1.72    \u001b[0m | \u001b[0m91.22    \u001b[0m | \u001b[0m-2.276   \u001b[0m | \u001b[0m17.14    \u001b[0m | \u001b[0m2.383    \u001b[0m | \u001b[0m-2.405   \u001b[0m |\n",
      "Train loss: 0.9278103918642611\n",
      "Test loss: 5.817687193552653\n",
      "| \u001b[0m51       \u001b[0m | \u001b[0m-5.818   \u001b[0m | \u001b[0m87.76    \u001b[0m | \u001b[0m-4.096   \u001b[0m | \u001b[0m22.18    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m-3.415   \u001b[0m |\n",
      "Train loss: 0.4407025939986311\n",
      "Test loss: 0.886757374741137\n",
      "| \u001b[0m52       \u001b[0m | \u001b[0m-0.8868  \u001b[0m | \u001b[0m94.59    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m18.11    \u001b[0m | \u001b[0m2.07     \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.39468975872355133\n",
      "Test loss: 1.6621769455571969\n",
      "| \u001b[0m53       \u001b[0m | \u001b[0m-1.662   \u001b[0m | \u001b[0m95.2     \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m35.65    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.38882100528634683\n",
      "Test loss: 0.7497085556387901\n",
      "| \u001b[0m54       \u001b[0m | \u001b[0m-0.7497  \u001b[0m | \u001b[0m105.3    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m33.63    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 0.5836317922315888\n",
      "Test loss: 2.352116022258997\n",
      "| \u001b[0m55       \u001b[0m | \u001b[0m-2.352   \u001b[0m | \u001b[0m104.2    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m31.99    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 1.010251774175747\n",
      "Test loss: 6.144625554482142\n",
      "| \u001b[0m56       \u001b[0m | \u001b[0m-6.145   \u001b[0m | \u001b[0m96.88    \u001b[0m | \u001b[0m-2.918   \u001b[0m | \u001b[0m15.64    \u001b[0m | \u001b[0m2.717    \u001b[0m | \u001b[0m-2.859   \u001b[0m |\n",
      "Train loss: 0.4668227110460803\n",
      "Test loss: 1.6735060724119346\n",
      "| \u001b[0m57       \u001b[0m | \u001b[0m-1.674   \u001b[0m | \u001b[0m89.85    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m23.64    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.9831199247289348\n",
      "Test loss: 5.74317142367363\n",
      "| \u001b[0m58       \u001b[0m | \u001b[0m-5.743   \u001b[0m | \u001b[0m108.3    \u001b[0m | \u001b[0m-4.061   \u001b[0m | \u001b[0m34.61    \u001b[0m | \u001b[0m2.386    \u001b[0m | \u001b[0m-4.964   \u001b[0m |\n",
      "Train loss: 0.5070827390897918\n",
      "Test loss: 1.215592655663689\n",
      "| \u001b[0m59       \u001b[0m | \u001b[0m-1.216   \u001b[0m | \u001b[0m105.0    \u001b[0m | \u001b[0m-2.1     \u001b[0m | \u001b[0m21.94    \u001b[0m | \u001b[0m3.005    \u001b[0m | \u001b[0m-2.269   \u001b[0m |\n",
      "Train loss: 0.8192683601298848\n",
      "Test loss: 4.754375030597051\n",
      "| \u001b[0m60       \u001b[0m | \u001b[0m-4.754   \u001b[0m | \u001b[0m105.3    \u001b[0m | \u001b[0m-2.904   \u001b[0m | \u001b[0m22.36    \u001b[0m | \u001b[0m2.948    \u001b[0m | \u001b[0m-4.644   \u001b[0m |\n",
      "Train loss: 1.0042541114663757\n",
      "Test loss: 6.738421579202016\n",
      "| \u001b[0m61       \u001b[0m | \u001b[0m-6.738   \u001b[0m | \u001b[0m96.19    \u001b[0m | \u001b[0m-4.503   \u001b[0m | \u001b[0m41.63    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-4.204   \u001b[0m |\n",
      "Train loss: 0.4662676793900696\n",
      "Test loss: 1.8717603099842866\n",
      "| \u001b[0m62       \u001b[0m | \u001b[0m-1.872   \u001b[0m | \u001b[0m103.5    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m34.63    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m-3.439   \u001b[0m |\n",
      "Train loss: 0.5868186704008966\n",
      "Test loss: 1.1642124727368355\n",
      "| \u001b[0m63       \u001b[0m | \u001b[0m-1.164   \u001b[0m | \u001b[0m101.4    \u001b[0m | \u001b[0m-2.44    \u001b[0m | \u001b[0m31.1     \u001b[0m | \u001b[0m2.489    \u001b[0m | \u001b[0m-4.349   \u001b[0m |\n",
      "Train loss: 0.9526253088906005\n",
      "Test loss: 5.239863107601802\n",
      "| \u001b[0m64       \u001b[0m | \u001b[0m-5.24    \u001b[0m | \u001b[0m100.9    \u001b[0m | \u001b[0m-2.976   \u001b[0m | \u001b[0m32.53    \u001b[0m | \u001b[0m2.044    \u001b[0m | \u001b[0m-2.122   \u001b[0m |\n",
      "Train loss: 0.45977708639740644\n",
      "Test loss: 1.5574898055444162\n",
      "| \u001b[0m65       \u001b[0m | \u001b[0m-1.557   \u001b[0m | \u001b[0m93.22    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m18.82    \u001b[0m | \u001b[0m3.65     \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.5459684129754031\n",
      "Test loss: 1.2051084789757927\n",
      "| \u001b[0m66       \u001b[0m | \u001b[0m-1.205   \u001b[0m | \u001b[0m102.3    \u001b[0m | \u001b[0m-2.166   \u001b[0m | \u001b[0m22.43    \u001b[0m | \u001b[0m3.449    \u001b[0m | \u001b[0m-2.026   \u001b[0m |\n",
      "Train loss: 0.4062460255683274\n",
      "Test loss: 1.101502465705077\n",
      "| \u001b[0m67       \u001b[0m | \u001b[0m-1.102   \u001b[0m | \u001b[0m103.3    \u001b[0m | \u001b[0m-2.008   \u001b[0m | \u001b[0m19.39    \u001b[0m | \u001b[0m3.024    \u001b[0m | \u001b[0m-2.088   \u001b[0m |\n",
      "Train loss: 0.8785146170270604\n",
      "Test loss: 5.3646460970242815\n",
      "| \u001b[0m68       \u001b[0m | \u001b[0m-5.365   \u001b[0m | \u001b[0m106.0    \u001b[0m | \u001b[0m-2.999   \u001b[0m | \u001b[0m18.98    \u001b[0m | \u001b[0m3.0      \u001b[0m | \u001b[0m-2.192   \u001b[0m |\n",
      "Train loss: 0.5082291544641595\n",
      "Test loss: 1.1070576334993045\n",
      "| \u001b[0m69       \u001b[0m | \u001b[0m-1.107   \u001b[0m | \u001b[0m106.7    \u001b[0m | \u001b[0m-2.255   \u001b[0m | \u001b[0m34.94    \u001b[0m | \u001b[0m2.817    \u001b[0m | \u001b[0m-2.667   \u001b[0m |\n",
      "Train loss: 0.5310887148654139\n",
      "Test loss: 1.8263658167173464\n",
      "| \u001b[0m70       \u001b[0m | \u001b[0m-1.826   \u001b[0m | \u001b[0m89.42    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m18.44    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.45667813813968283\n",
      "Test loss: 1.4878119093676407\n",
      "| \u001b[0m71       \u001b[0m | \u001b[0m-1.488   \u001b[0m | \u001b[0m103.1    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m21.24    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.3216465735757673\n",
      "Test loss: 0.6311664121846358\n",
      "| \u001b[95m72       \u001b[0m | \u001b[95m-0.6312  \u001b[0m | \u001b[95m86.07    \u001b[0m | \u001b[95m-2.0     \u001b[0m | \u001b[95m23.1     \u001b[0m | \u001b[95m4.0      \u001b[0m | \u001b[95m-2.0     \u001b[0m |\n",
      "Train loss: 0.5740249788237585\n",
      "Test loss: 1.531510119015972\n",
      "| \u001b[0m73       \u001b[0m | \u001b[0m-1.532   \u001b[0m | \u001b[0m83.37    \u001b[0m | \u001b[0m-2.246   \u001b[0m | \u001b[0m22.14    \u001b[0m | \u001b[0m3.587    \u001b[0m | \u001b[0m-3.13    \u001b[0m |\n",
      "Train loss: 0.41340290483187986\n",
      "Test loss: 1.0070388199140627\n",
      "| \u001b[0m74       \u001b[0m | \u001b[0m-1.007   \u001b[0m | \u001b[0m85.22    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m24.0     \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-4.464   \u001b[0m |\n",
      "Train loss: 0.3432623782209703\n",
      "Test loss: 1.6035910360515118\n",
      "| \u001b[0m75       \u001b[0m | \u001b[0m-1.604   \u001b[0m | \u001b[0m84.56    \u001b[0m | \u001b[0m-2.055   \u001b[0m | \u001b[0m25.38    \u001b[0m | \u001b[0m3.998    \u001b[0m | \u001b[0m-2.443   \u001b[0m |\n",
      "Train loss: 0.8900103973023392\n",
      "Test loss: 5.083263556162517\n",
      "| \u001b[0m76       \u001b[0m | \u001b[0m-5.083   \u001b[0m | \u001b[0m81.82    \u001b[0m | \u001b[0m-2.793   \u001b[0m | \u001b[0m24.66    \u001b[0m | \u001b[0m3.607    \u001b[0m | \u001b[0m-4.209   \u001b[0m |\n",
      "Train loss: 1.1892058640919827\n",
      "Test loss: 5.8604826629161835\n",
      "| \u001b[0m77       \u001b[0m | \u001b[0m-5.86    \u001b[0m | \u001b[0m97.58    \u001b[0m | \u001b[0m-2.49    \u001b[0m | \u001b[0m8.498    \u001b[0m | \u001b[0m2.095    \u001b[0m | \u001b[0m-4.028   \u001b[0m |\n",
      "Train loss: 0.5021176811030789\n",
      "Test loss: 1.3554329508915544\n",
      "| \u001b[0m78       \u001b[0m | \u001b[0m-1.355   \u001b[0m | \u001b[0m84.61    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m20.25    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.42058983440133363\n",
      "Test loss: 0.9373306737591823\n",
      "| \u001b[0m79       \u001b[0m | \u001b[0m-0.9373  \u001b[0m | \u001b[0m85.38    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m21.25    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-4.885   \u001b[0m |\n",
      "Train loss: 0.5292745962537624\n",
      "Test loss: 1.6819725378106039\n",
      "| \u001b[0m80       \u001b[0m | \u001b[0m-1.682   \u001b[0m | \u001b[0m101.4    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m17.95    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.9783718983667928\n",
      "Test loss: 4.834891840815544\n",
      "| \u001b[0m81       \u001b[0m | \u001b[0m-4.835   \u001b[0m | \u001b[0m84.16    \u001b[0m | \u001b[0m-3.265   \u001b[0m | \u001b[0m17.89    \u001b[0m | \u001b[0m2.962    \u001b[0m | \u001b[0m-4.63    \u001b[0m |\n",
      "Train loss: 0.35209135353766585\n",
      "Test loss: 0.6283877541621526\n",
      "| \u001b[95m82       \u001b[0m | \u001b[95m-0.6284  \u001b[0m | \u001b[95m99.32    \u001b[0m | \u001b[95m-2.07    \u001b[0m | \u001b[95m39.38    \u001b[0m | \u001b[95m2.933    \u001b[0m | \u001b[95m-2.094   \u001b[0m |\n",
      "Train loss: 0.937931361029277\n",
      "Test loss: 5.3279876212279005\n",
      "| \u001b[0m83       \u001b[0m | \u001b[0m-5.328   \u001b[0m | \u001b[0m102.4    \u001b[0m | \u001b[0m-3.242   \u001b[0m | \u001b[0m40.36    \u001b[0m | \u001b[0m3.178    \u001b[0m | \u001b[0m-2.215   \u001b[0m |\n",
      "Train loss: 0.38101419360955824\n",
      "Test loss: 1.5953027550131083\n",
      "| \u001b[0m84       \u001b[0m | \u001b[0m-1.595   \u001b[0m | \u001b[0m92.13    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m25.27    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 0.39740054820337006\n",
      "Test loss: 1.2198901704202096\n",
      "| \u001b[0m85       \u001b[0m | \u001b[0m-1.22    \u001b[0m | \u001b[0m95.05    \u001b[0m | \u001b[0m-2.012   \u001b[0m | \u001b[0m27.08    \u001b[0m | \u001b[0m3.683    \u001b[0m | \u001b[0m-4.091   \u001b[0m |\n",
      "Train loss: 0.7199177919207392\n",
      "Test loss: 2.1533993929624557\n",
      "| \u001b[0m86       \u001b[0m | \u001b[0m-2.153   \u001b[0m | \u001b[0m93.23    \u001b[0m | \u001b[0m-2.356   \u001b[0m | \u001b[0m26.57    \u001b[0m | \u001b[0m2.017    \u001b[0m | \u001b[0m-3.929   \u001b[0m |\n",
      "Train loss: 0.682158954743598\n",
      "Test loss: 1.5678738268713157\n",
      "| \u001b[0m87       \u001b[0m | \u001b[0m-1.568   \u001b[0m | \u001b[0m94.84    \u001b[0m | \u001b[0m-2.445   \u001b[0m | \u001b[0m30.33    \u001b[0m | \u001b[0m3.391    \u001b[0m | \u001b[0m-2.754   \u001b[0m |\n",
      "Train loss: 0.9113776495529188\n",
      "Test loss: 5.554806421200435\n",
      "| \u001b[0m88       \u001b[0m | \u001b[0m-5.555   \u001b[0m | \u001b[0m94.31    \u001b[0m | \u001b[0m-4.201   \u001b[0m | \u001b[0m28.61    \u001b[0m | \u001b[0m3.025    \u001b[0m | \u001b[0m-4.558   \u001b[0m |\n",
      "Train loss: 0.377989047370549\n",
      "Test loss: 1.6574140563607216\n",
      "| \u001b[0m89       \u001b[0m | \u001b[0m-1.657   \u001b[0m | \u001b[0m99.54    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m30.11    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-5.0     \u001b[0m |\n",
      "Train loss: 0.46589406526874044\n",
      "Test loss: 1.8533853155871232\n",
      "| \u001b[0m90       \u001b[0m | \u001b[0m-1.853   \u001b[0m | \u001b[0m93.56    \u001b[0m | \u001b[0m-2.106   \u001b[0m | \u001b[0m32.86    \u001b[0m | \u001b[0m3.948    \u001b[0m | \u001b[0m-3.701   \u001b[0m |\n",
      "Train loss: 0.3888924526352737\n",
      "Test loss: 1.0314187286421657\n",
      "| \u001b[0m91       \u001b[0m | \u001b[0m-1.031   \u001b[0m | \u001b[0m107.0    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m33.08    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "Train loss: 0.6927846202979216\n",
      "Test loss: 1.738178529466192\n",
      "| \u001b[0m92       \u001b[0m | \u001b[0m-1.738   \u001b[0m | \u001b[0m95.65    \u001b[0m | \u001b[0m-2.237   \u001b[0m | \u001b[0m23.29    \u001b[0m | \u001b[0m3.838    \u001b[0m | \u001b[0m-4.161   \u001b[0m |\n",
      "Train loss: 0.8616438275718525\n",
      "Test loss: 4.8602368136247\n",
      "| \u001b[0m93       \u001b[0m | \u001b[0m-4.86    \u001b[0m | \u001b[0m34.1     \u001b[0m | \u001b[0m-3.224   \u001b[0m | \u001b[0m63.75    \u001b[0m | \u001b[0m2.654    \u001b[0m | \u001b[0m-2.603   \u001b[0m |\n",
      "Train loss: 0.5561152937494822\n",
      "Test loss: 1.1210723655919235\n",
      "| \u001b[0m94       \u001b[0m | \u001b[0m-1.121   \u001b[0m | \u001b[0m1.368    \u001b[0m | \u001b[0m-2.427   \u001b[0m | \u001b[0m56.28    \u001b[0m | \u001b[0m2.761    \u001b[0m | \u001b[0m-2.592   \u001b[0m |\n",
      "Train loss: 0.9511568749172462\n",
      "Test loss: 6.144146770238876\n",
      "| \u001b[0m95       \u001b[0m | \u001b[0m-6.144   \u001b[0m | \u001b[0m2.757    \u001b[0m | \u001b[0m-3.944   \u001b[0m | \u001b[0m57.42    \u001b[0m | \u001b[0m3.69     \u001b[0m | \u001b[0m-3.963   \u001b[0m |\n",
      "Train loss: 0.47251994262222907\n",
      "Test loss: 1.4359504772971075\n",
      "| \u001b[0m96       \u001b[0m | \u001b[0m-1.436   \u001b[0m | \u001b[0m1.707    \u001b[0m | \u001b[0m-2.21    \u001b[0m | \u001b[0m52.75    \u001b[0m | \u001b[0m2.57     \u001b[0m | \u001b[0m-3.236   \u001b[0m |\n",
      "Train loss: 0.9496792275285525\n",
      "Test loss: 5.845008015632629\n",
      "| \u001b[0m97       \u001b[0m | \u001b[0m-5.845   \u001b[0m | \u001b[0m1.281    \u001b[0m | \u001b[0m-3.734   \u001b[0m | \u001b[0m54.56    \u001b[0m | \u001b[0m2.894    \u001b[0m | \u001b[0m-2.063   \u001b[0m |\n",
      "Train loss: 0.4638306216613666\n",
      "Test loss: 1.5098713313539822\n",
      "| \u001b[0m98       \u001b[0m | \u001b[0m-1.51    \u001b[0m | \u001b[0m85.76    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m22.11    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-3.354   \u001b[0m |\n",
      "Train loss: 0.43327079766518056\n",
      "Test loss: 1.840086316068967\n",
      "| \u001b[0m99       \u001b[0m | \u001b[0m-1.84    \u001b[0m | \u001b[0m95.51    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m25.52    \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m-2.317   \u001b[0m |\n",
      "Train loss: 0.465995867565161\n",
      "Test loss: 1.384668945024411\n",
      "| \u001b[0m100      \u001b[0m | \u001b[0m-1.385   \u001b[0m | \u001b[0m99.18    \u001b[0m | \u001b[0m-2.183   \u001b[0m | \u001b[0m38.04    \u001b[0m | \u001b[0m3.883    \u001b[0m | \u001b[0m-3.082   \u001b[0m |\n",
      "Train loss: 0.39514567803692174\n",
      "Test loss: 1.7135499591628711\n",
      "| \u001b[0m101      \u001b[0m | \u001b[0m-1.714   \u001b[0m | \u001b[0m2.008    \u001b[0m | \u001b[0m-2.085   \u001b[0m | \u001b[0m51.59    \u001b[0m | \u001b[0m2.991    \u001b[0m | \u001b[0m-4.886   \u001b[0m |\n",
      "Train loss: 0.38400311992390435\n",
      "Test loss: 1.1959119184563558\n",
      "| \u001b[0m102      \u001b[0m | \u001b[0m-1.196   \u001b[0m | \u001b[0m3.472    \u001b[0m | \u001b[0m-2.178   \u001b[0m | \u001b[0m50.9     \u001b[0m | \u001b[0m3.38     \u001b[0m | \u001b[0m-2.504   \u001b[0m |\n",
      "Train loss: 0.301297917811049\n",
      "Test loss: 1.1311451426396768\n",
      "| \u001b[0m103      \u001b[0m | \u001b[0m-1.131   \u001b[0m | \u001b[0m1.768    \u001b[0m | \u001b[0m-2.026   \u001b[0m | \u001b[0m50.69    \u001b[0m | \u001b[0m2.181    \u001b[0m | \u001b[0m-2.497   \u001b[0m |\n",
      "Train loss: 0.41679518523852566\n",
      "Test loss: 1.5088816707332928\n",
      "| \u001b[0m104      \u001b[0m | \u001b[0m-1.509   \u001b[0m | \u001b[0m4.374    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m52.21    \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m-3.777   \u001b[0m |\n",
      "Train loss: 0.4012731156072806\n",
      "Test loss: 1.246738038957119\n",
      "| \u001b[0m105      \u001b[0m | \u001b[0m-1.247   \u001b[0m | \u001b[0m3.732    \u001b[0m | \u001b[0m-2.0     \u001b[0m | \u001b[0m49.0     \u001b[0m | \u001b[0m2.0      \u001b[0m | \u001b[0m-3.835   \u001b[0m |\n",
      "=====================================================================================\n",
      "{'target': -0.6283877541621526, 'params': {'batch_size': 99.31767143479107, 'learning_rate_log': -2.069745681191904, 'num_hidden_size': 39.38436488302246, 'num_layers': 2.933324195350682, 'weight_decay': -2.0942049532924525}}\n"
     ]
    }
   ],
   "source": [
    "def train_model(data_loader, model, loss_function, optimizer):\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for X, y in data_loader:\n",
    "        output = model(X)\n",
    "        loss = loss_function(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Train loss: {avg_loss}\")\n",
    "    return avg_loss\n",
    "\n",
    "def test_model(data_loader, model, loss_function):\n",
    "    \n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            output = model(X)\n",
    "            total_loss += loss_function(output, y).item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Test loss: {avg_loss}\")\n",
    "    return avg_loss\n",
    "\n",
    "# Define the function to be optimized\n",
    "def evaluate_model(learning_rate_log, num_hidden_size, num_layers, weight_decay, batch_size):\n",
    "    learning_rate = 10 ** learning_rate_log\n",
    "    num_hidden_size = int(num_hidden_size)\n",
    "    num_layers = int(num_layers)\n",
    "    weight_decay = 10 ** weight_decay\n",
    "    batch_size = int(batch_size)\n",
    "\n",
    "    # Reinitialize the model with new parameters\n",
    "    model = ShallowRegressionLSTM(hidden_size=num_hidden_size, num_layers=num_layers)\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    # Train and test the model\n",
    "    train_model(train_loader, model, loss_function, optimizer)\n",
    "    test_loss = test_model(test_loader, model, loss_function)\n",
    "    \n",
    "    # Return the negative test loss because BayesianOptimization maximize the function\n",
    "    return -test_loss\n",
    "\n",
    "\n",
    "# Define the hyperparameters range\n",
    "hyperparameters_range = {\n",
    "    'learning_rate_log': (-5, -2),  # we optimize in log scale\n",
    "    'num_hidden_size': (1, 64),  # assuming 50 is a sensible upper limit\n",
    "    'num_layers': (2, 4),  # range of layers\n",
    "    'weight_decay': (-5, -2),  # weight decay in log scale\n",
    "    'batch_size': (1, len(df_train))\n",
    "}\n",
    "# Initialize the optimizer\n",
    "bayesian_optimizer = BayesianOptimization(\n",
    "    f=evaluate_model,\n",
    "    pbounds=hyperparameters_range,\n",
    "    verbose=2,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# Maximize the evaluation function\n",
    "bayesian_optimizer.maximize(init_points=5, n_iter=100)\n",
    "\n",
    "# Print the best parameters\n",
    "print(bayesian_optimizer.max)\n",
    "\n",
    "best_params = bayesian_optimizer.max['params']\n",
    "\n",
    "# Re-calculate the learning rate from its logarithm\n",
    "best_params['learning_rate_log'] = 10 ** best_params['learning_rate_log']\n",
    "\n",
    "# Ensure hidden_size and num_layers are integers\n",
    "best_params['num_hidden_size'] = int(round(best_params['num_hidden_size']))\n",
    "best_params['num_layers'] = int(round(best_params['num_layers']))\n",
    "\n",
    "# Train a new model with the best parameters\n",
    "model = ShallowRegressionLSTM(hidden_size=best_params['num_hidden_size'], num_layers=best_params['num_layers'])\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), best_params['learning_rate_log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained test\n",
      "--------\n",
      "Test loss: 5.680697808663051\n",
      "\n",
      "Epoch 0\n",
      "---------\n",
      "Train loss: 0.30685007224815924\n",
      "Test loss: 1.1879057701056202\n",
      "\n",
      "Epoch 1\n",
      "---------\n",
      "Train loss: 0.20473311501681\n",
      "Test loss: 1.5661089196801186\n",
      "\n",
      "Epoch 2\n",
      "---------\n",
      "Train loss: 0.15730988850968108\n",
      "Test loss: 0.8727558869868517\n",
      "\n",
      "Epoch 3\n",
      "---------\n",
      "Train loss: 0.12656136380659566\n",
      "Test loss: 0.5225311828156313\n",
      "\n",
      "Epoch 4\n",
      "---------\n",
      "Train loss: 0.12077456325091221\n",
      "Test loss: 0.5578105685611566\n",
      "\n",
      "Epoch 5\n",
      "---------\n",
      "Train loss: 0.1098213122805228\n",
      "Test loss: 0.46142367646098137\n",
      "\n",
      "Epoch 6\n",
      "---------\n",
      "Train loss: 0.09281888646325348\n",
      "Test loss: 0.6759897371133169\n",
      "\n",
      "Epoch 7\n",
      "---------\n",
      "Train loss: 0.08540668594650924\n",
      "Test loss: 0.479970995336771\n",
      "\n",
      "Epoch 8\n",
      "---------\n",
      "Train loss: 0.07450683708176822\n",
      "Test loss: 0.47446321571866673\n",
      "\n",
      "Epoch 9\n",
      "---------\n",
      "Train loss: 0.07708164036424982\n",
      "Test loss: 0.296321173508962\n",
      "\n",
      "Epoch 10\n",
      "---------\n",
      "Train loss: 0.07262223566303382\n",
      "Test loss: 0.4045080095529556\n",
      "\n",
      "Epoch 11\n",
      "---------\n",
      "Train loss: 0.07471286626910237\n",
      "Test loss: 0.43348697076241177\n",
      "\n",
      "Epoch 12\n",
      "---------\n",
      "Train loss: 0.0795541777829262\n",
      "Test loss: 0.40672579904397327\n",
      "\n",
      "Epoch 13\n",
      "---------\n",
      "Train loss: 0.08020944117153114\n",
      "Test loss: 0.41950807472070056\n",
      "\n",
      "Epoch 14\n",
      "---------\n",
      "Train loss: 0.07550208665732597\n",
      "Test loss: 0.48789198820789653\n",
      "\n",
      "Epoch 15\n",
      "---------\n",
      "Train loss: 0.07825626974069588\n",
      "Test loss: 0.5110956144829591\n",
      "\n",
      "Epoch 16\n",
      "---------\n",
      "Train loss: 0.07749944167035455\n",
      "Test loss: 0.38537609080473584\n",
      "\n",
      "Epoch 17\n",
      "---------\n",
      "Train loss: 0.07137240267616722\n",
      "Test loss: 0.5028542876243591\n",
      "\n",
      "Epoch 18\n",
      "---------\n",
      "Train loss: 0.07338601742820763\n",
      "Test loss: 0.32007872437437374\n",
      "\n",
      "Epoch 19\n",
      "---------\n",
      "Train loss: 0.07611147343885859\n",
      "Test loss: 0.6291622084875902\n",
      "\n",
      "Epoch 20\n",
      "---------\n",
      "Train loss: 0.08822974819387938\n",
      "Test loss: 0.5832458144674698\n",
      "\n",
      "Epoch 21\n",
      "---------\n",
      "Train loss: 0.07776708105528676\n",
      "Test loss: 0.7049416887263457\n",
      "\n",
      "Epoch 22\n",
      "---------\n",
      "Train loss: 0.08454919608964308\n",
      "Test loss: 0.4259315747767687\n",
      "\n",
      "Epoch 23\n",
      "---------\n",
      "Train loss: 0.0734030904651091\n",
      "Test loss: 0.332161075125138\n",
      "\n",
      "Epoch 24\n",
      "---------\n",
      "Train loss: 0.08309520290208024\n",
      "Test loss: 0.41251976663867634\n",
      "\n",
      "Epoch 25\n",
      "---------\n",
      "Train loss: 0.08008009581700773\n",
      "Test loss: 0.5265346616506577\n",
      "\n",
      "Epoch 26\n",
      "---------\n",
      "Train loss: 0.07271764588517111\n",
      "Test loss: 0.5833483549455801\n",
      "\n",
      "Epoch 27\n",
      "---------\n",
      "Train loss: 0.07535642124964176\n",
      "Test loss: 0.3612230084836483\n",
      "\n",
      "Epoch 28\n",
      "---------\n",
      "Train loss: 0.0750990675837415\n",
      "Test loss: 0.3316785941521327\n",
      "\n",
      "Epoch 29\n",
      "---------\n",
      "Train loss: 0.07197114414963368\n",
      "Test loss: 0.46843294364710647\n",
      "\n",
      "Epoch 30\n",
      "---------\n",
      "Train loss: 0.08023660904350313\n",
      "Test loss: 0.5480144588897625\n",
      "\n",
      "Epoch 31\n",
      "---------\n",
      "Train loss: 0.08036295479994167\n",
      "Test loss: 0.4722930130859216\n",
      "\n",
      "Epoch 32\n",
      "---------\n",
      "Train loss: 0.07943321990849753\n",
      "Test loss: 0.5572304297238588\n",
      "\n",
      "Epoch 33\n",
      "---------\n",
      "Train loss: 0.08074064737789936\n",
      "Test loss: 0.5098718851804733\n",
      "\n",
      "Epoch 34\n",
      "---------\n",
      "Train loss: 0.07605106097557959\n",
      "Test loss: 0.285547336563468\n",
      "\n",
      "Epoch 35\n",
      "---------\n",
      "Train loss: 0.08153318884354588\n",
      "Test loss: 0.33016087921957177\n",
      "\n",
      "Epoch 36\n",
      "---------\n",
      "Train loss: 0.07262800962465966\n",
      "Test loss: 0.4666194984068473\n",
      "\n",
      "Epoch 37\n",
      "---------\n",
      "Train loss: 0.07482596655451768\n",
      "Test loss: 0.35375047102570534\n",
      "\n",
      "Epoch 38\n",
      "---------\n",
      "Train loss: 0.08154433071172822\n",
      "Test loss: 0.3611748870462179\n",
      "\n",
      "Epoch 39\n",
      "---------\n",
      "Train loss: 0.07453681776501439\n",
      "Test loss: 0.59185441583395\n",
      "\n",
      "Epoch 40\n",
      "---------\n",
      "Train loss: 0.07682468968984746\n",
      "Test loss: 0.7203361528615156\n",
      "\n",
      "Epoch 41\n",
      "---------\n",
      "Train loss: 0.0771985743320673\n",
      "Test loss: 0.37408827369411785\n",
      "\n",
      "Epoch 42\n",
      "---------\n",
      "Train loss: 0.07838726564109125\n",
      "Test loss: 0.47590925234059495\n",
      "\n",
      "Epoch 43\n",
      "---------\n",
      "Train loss: 0.0717358188326093\n",
      "Test loss: 0.3401525678733985\n",
      "\n",
      "Epoch 44\n",
      "---------\n",
      "Train loss: 0.08052105780036466\n",
      "Test loss: 0.6833595292021831\n",
      "\n",
      "Epoch 45\n",
      "---------\n",
      "Train loss: 0.06670886249205954\n",
      "Test loss: 0.5143549386411905\n",
      "\n",
      "Epoch 46\n",
      "---------\n",
      "Train loss: 0.06904279217879111\n",
      "Test loss: 0.42123774625360966\n",
      "\n",
      "Epoch 47\n",
      "---------\n",
      "Train loss: 0.07043585989221528\n",
      "Test loss: 0.48588730705281097\n",
      "\n",
      "Epoch 48\n",
      "---------\n",
      "Train loss: 0.06463766980261819\n",
      "Test loss: 0.5238773406793674\n",
      "\n",
      "Epoch 49\n",
      "---------\n",
      "Train loss: 0.06663550293180034\n",
      "Test loss: 0.3315264067302148\n",
      "\n",
      "Epoch 50\n",
      "---------\n",
      "Train loss: 0.07203645439113716\n",
      "Test loss: 0.39686707003662985\n",
      "\n",
      "Epoch 51\n",
      "---------\n",
      "Train loss: 0.06613732363424592\n",
      "Test loss: 0.4493001302083333\n",
      "\n",
      "Epoch 52\n",
      "---------\n",
      "Train loss: 0.07207932091645293\n",
      "Test loss: 0.5185554772615433\n",
      "\n",
      "Epoch 53\n",
      "---------\n",
      "Train loss: 0.07138631993753684\n",
      "Test loss: 0.38705469978352386\n",
      "\n",
      "Epoch 54\n",
      "---------\n",
      "Train loss: 0.06480666708100487\n",
      "Test loss: 0.48116107036670047\n",
      "\n",
      "Epoch 55\n",
      "---------\n",
      "Train loss: 0.0656093057698092\n",
      "Test loss: 0.5148398093879223\n",
      "\n",
      "Epoch 56\n",
      "---------\n",
      "Train loss: 0.06851351282534164\n",
      "Test loss: 0.5134596352775892\n",
      "\n",
      "Epoch 57\n",
      "---------\n",
      "Train loss: 0.06257956262325516\n",
      "Test loss: 0.5322449163844188\n",
      "\n",
      "Epoch 58\n",
      "---------\n",
      "Train loss: 0.06250710472434277\n",
      "Test loss: 0.441730547696352\n",
      "\n",
      "Epoch 59\n",
      "---------\n",
      "Train loss: 0.06398934405297041\n",
      "Test loss: 0.3446337943896651\n",
      "\n",
      "Epoch 60\n",
      "---------\n",
      "Train loss: 0.06851447401316585\n",
      "Test loss: 0.42222518225510913\n",
      "\n",
      "Epoch 61\n",
      "---------\n",
      "Train loss: 0.060017876380525935\n",
      "Test loss: 0.5911209248006344\n",
      "\n",
      "Epoch 62\n",
      "---------\n",
      "Train loss: 0.06169106782967779\n",
      "Test loss: 0.3879896261108418\n",
      "\n",
      "Epoch 63\n",
      "---------\n",
      "Train loss: 0.06435530873116206\n",
      "Test loss: 0.3879497641076644\n",
      "\n",
      "Epoch 64\n",
      "---------\n",
      "Train loss: 0.07956124732673571\n",
      "Test loss: 0.6780680182079474\n",
      "\n",
      "Epoch 65\n",
      "---------\n",
      "Train loss: 0.07915266138828687\n",
      "Test loss: 0.33504297118633986\n",
      "\n",
      "Epoch 66\n",
      "---------\n",
      "Train loss: 0.06593453078656583\n",
      "Test loss: 0.496592886125048\n",
      "\n",
      "Epoch 67\n",
      "---------\n",
      "Train loss: 0.06269690244634812\n",
      "Test loss: 0.5269791384538015\n",
      "\n",
      "Epoch 68\n",
      "---------\n",
      "Train loss: 0.06336137354122223\n",
      "Test loss: 0.48131682599584263\n",
      "\n",
      "Epoch 69\n",
      "---------\n",
      "Train loss: 0.06148213616295441\n",
      "Test loss: 0.3958907872438431\n",
      "\n",
      "Epoch 70\n",
      "---------\n",
      "Train loss: 0.06309856314564476\n",
      "Test loss: 0.41470935257772606\n",
      "\n",
      "Epoch 71\n",
      "---------\n",
      "Train loss: 0.058673858801506176\n",
      "Test loss: 0.5156876556575298\n",
      "\n",
      "Epoch 72\n",
      "---------\n",
      "Train loss: 0.0589829559022611\n",
      "Test loss: 0.4210784913351138\n",
      "\n",
      "Epoch 73\n",
      "---------\n",
      "Train loss: 0.06855509374480716\n",
      "Test loss: 0.49544262575606507\n",
      "\n",
      "Epoch 74\n",
      "---------\n",
      "Train loss: 0.06318806789538546\n",
      "Test loss: 0.7214803112049898\n",
      "\n",
      "Epoch 75\n",
      "---------\n",
      "Train loss: 0.06609305315273437\n",
      "Test loss: 0.4244320883105199\n",
      "\n",
      "Epoch 76\n",
      "---------\n",
      "Train loss: 0.07317957332408107\n",
      "Test loss: 0.36852894983409595\n",
      "\n",
      "Epoch 77\n",
      "---------\n",
      "Train loss: 0.07998522814375826\n",
      "Test loss: 0.40823958069086075\n",
      "\n",
      "Epoch 78\n",
      "---------\n",
      "Train loss: 0.06707978870316937\n",
      "Test loss: 0.49411274554828805\n",
      "\n",
      "Epoch 79\n",
      "---------\n",
      "Train loss: 0.06019092095713761\n",
      "Test loss: 0.4172498794893424\n",
      "\n",
      "Epoch 80\n",
      "---------\n",
      "Train loss: 0.057903483308650354\n",
      "Test loss: 0.44633391002813977\n",
      "\n",
      "Epoch 81\n",
      "---------\n",
      "Train loss: 0.0594296817444784\n",
      "Test loss: 0.4388925985743602\n",
      "\n",
      "Epoch 82\n",
      "---------\n",
      "Train loss: 0.05898704445241271\n",
      "Test loss: 0.39696040532241267\n",
      "\n",
      "Epoch 83\n",
      "---------\n",
      "Train loss: 0.05611026830769874\n",
      "Test loss: 0.4914425847431024\n",
      "\n",
      "Epoch 84\n",
      "---------\n",
      "Train loss: 0.0640787762916974\n",
      "Test loss: 0.45261263598998386\n",
      "\n",
      "Epoch 85\n",
      "---------\n",
      "Train loss: 0.06317604951107421\n",
      "Test loss: 0.37205145818491775\n",
      "\n",
      "Epoch 86\n",
      "---------\n",
      "Train loss: 0.062380429231435865\n",
      "Test loss: 0.4272677681098382\n",
      "\n",
      "Epoch 87\n",
      "---------\n",
      "Train loss: 0.06216138712054974\n",
      "Test loss: 0.5201525477071604\n",
      "\n",
      "Epoch 88\n",
      "---------\n",
      "Train loss: 0.060163645463920126\n",
      "Test loss: 0.4073674753308296\n",
      "\n",
      "Epoch 89\n",
      "---------\n",
      "Train loss: 0.058374687853093084\n",
      "Test loss: 0.4507698478798072\n",
      "\n",
      "Epoch 90\n",
      "---------\n",
      "Train loss: 0.055726114490598035\n",
      "Test loss: 0.39488406851887703\n",
      "\n",
      "Epoch 91\n",
      "---------\n",
      "Train loss: 0.0601929354078665\n",
      "Test loss: 0.47992112922171754\n",
      "\n",
      "Epoch 92\n",
      "---------\n",
      "Train loss: 0.06251970677938615\n",
      "Test loss: 0.5574733975032965\n",
      "\n",
      "Epoch 93\n",
      "---------\n",
      "Train loss: 0.06153694562916014\n",
      "Test loss: 0.3593139825388789\n",
      "\n",
      "Epoch 94\n",
      "---------\n",
      "Train loss: 0.06256264870014117\n",
      "Test loss: 0.37065746169537306\n",
      "\n",
      "Epoch 95\n",
      "---------\n",
      "Train loss: 0.076460714804361\n",
      "Test loss: 1.0382195748388767\n",
      "\n",
      "Epoch 96\n",
      "---------\n",
      "Train loss: 0.07066215521882514\n",
      "Test loss: 0.3756048632785678\n",
      "\n",
      "Epoch 97\n",
      "---------\n",
      "Train loss: 0.07179529169524038\n",
      "Test loss: 0.35251189799358446\n",
      "\n",
      "Epoch 98\n",
      "---------\n",
      "Train loss: 0.06478247275525653\n",
      "Test loss: 0.47091200575232506\n",
      "\n",
      "Epoch 99\n",
      "---------\n",
      "Train loss: 0.06064011448541203\n",
      "Test loss: 0.5225065021465222\n",
      "\n",
      "Epoch 100\n",
      "---------\n",
      "Train loss: 0.059584621867444995\n",
      "Test loss: 0.4205999883512656\n",
      "\n",
      "Epoch 101\n",
      "---------\n",
      "Train loss: 0.06434496178455348\n",
      "Test loss: 0.4535681741933028\n",
      "\n",
      "Epoch 102\n",
      "---------\n",
      "Train loss: 0.06085144834139863\n",
      "Test loss: 0.3548864771922429\n",
      "\n",
      "Epoch 103\n",
      "---------\n",
      "Train loss: 0.0563292556089928\n",
      "Test loss: 0.533033637329936\n",
      "\n",
      "Epoch 104\n",
      "---------\n",
      "Train loss: 0.05829127362576892\n",
      "Test loss: 0.4613675760726134\n",
      "\n",
      "Epoch 105\n",
      "---------\n",
      "Train loss: 0.06222014159366891\n",
      "Test loss: 0.4600223693996668\n",
      "\n",
      "Epoch 106\n",
      "---------\n",
      "Train loss: 0.06746140588074923\n",
      "Test loss: 0.4334011133760214\n",
      "\n",
      "Epoch 107\n",
      "---------\n",
      "Train loss: 0.06138233793899417\n",
      "Test loss: 0.3400586470961571\n",
      "\n",
      "Epoch 108\n",
      "---------\n",
      "Train loss: 0.062062807230127824\n",
      "Test loss: 0.5554768753548464\n",
      "\n",
      "Epoch 109\n",
      "---------\n",
      "Train loss: 0.06585177475888584\n",
      "Test loss: 0.3912192539622386\n",
      "\n",
      "Epoch 110\n",
      "---------\n",
      "Train loss: 0.057746367717816216\n",
      "Test loss: 0.47515986921886605\n",
      "\n",
      "Epoch 111\n",
      "---------\n",
      "Train loss: 0.05583312887088018\n",
      "Test loss: 0.4503151085227728\n",
      "\n",
      "Epoch 112\n",
      "---------\n",
      "Train loss: 0.05813774187117815\n",
      "Test loss: 0.4293335775534312\n",
      "\n",
      "Epoch 113\n",
      "---------\n",
      "Train loss: 0.05634334893280489\n",
      "Test loss: 0.4977576670547326\n",
      "\n",
      "Epoch 114\n",
      "---------\n",
      "Train loss: 0.056847179610584234\n",
      "Test loss: 0.5154603651414315\n",
      "\n",
      "Epoch 115\n",
      "---------\n",
      "Train loss: 0.06131110997946077\n",
      "Test loss: 0.35589421167969704\n",
      "\n",
      "Epoch 116\n",
      "---------\n",
      "Train loss: 0.057711709504695355\n",
      "Test loss: 0.44356421070794266\n",
      "\n",
      "Epoch 117\n",
      "---------\n",
      "Train loss: 0.055121619310985144\n",
      "Test loss: 0.43096383288502693\n",
      "\n",
      "Epoch 118\n",
      "---------\n",
      "Train loss: 0.053179361816571166\n",
      "Test loss: 0.43458699993789196\n",
      "\n",
      "Epoch 119\n",
      "---------\n",
      "Train loss: 0.05540024241860453\n",
      "Test loss: 0.3931326648841302\n",
      "\n",
      "Epoch 120\n",
      "---------\n",
      "Train loss: 0.05475244584896073\n",
      "Test loss: 0.5617576166987419\n",
      "\n",
      "Epoch 121\n",
      "---------\n",
      "Train loss: 0.05449882138998726\n",
      "Test loss: 0.458257879751424\n",
      "\n",
      "Epoch 122\n",
      "---------\n",
      "Train loss: 0.06767526522555666\n",
      "Test loss: 0.39547118296225864\n",
      "\n",
      "Epoch 123\n",
      "---------\n",
      "Train loss: 0.054306243121548484\n",
      "Test loss: 0.4887266308069229\n",
      "\n",
      "Epoch 124\n",
      "---------\n",
      "Train loss: 0.05711700046132948\n",
      "Test loss: 0.47792506590485573\n",
      "\n",
      "Epoch 125\n",
      "---------\n",
      "Train loss: 0.05284102159124371\n",
      "Test loss: 0.4003963824361563\n",
      "\n",
      "Epoch 126\n",
      "---------\n",
      "Train loss: 0.054916406956476135\n",
      "Test loss: 0.41533276873330277\n",
      "\n",
      "Epoch 127\n",
      "---------\n",
      "Train loss: 0.06037511586662338\n",
      "Test loss: 0.5041436577836672\n",
      "\n",
      "Epoch 128\n",
      "---------\n",
      "Train loss: 0.059503561307399255\n",
      "Test loss: 0.35913364837567013\n",
      "\n",
      "Epoch 129\n",
      "---------\n",
      "Train loss: 0.05394678156369844\n",
      "Test loss: 0.6587581417212883\n",
      "\n",
      "Hidden SİZE XD 39\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            lead1  Model forecast\n",
      "Month                            \n",
      "1949-01-01  118.0      124.148689\n",
      "1949-02-01  132.0      129.379440\n",
      "1949-03-01  129.0      140.329727\n",
      "1949-04-01  121.0      134.113174\n",
      "1949-05-01  135.0      130.181519\n",
      "...           ...             ...\n",
      "1960-07-01  606.0      532.004944\n",
      "1960-08-01  508.0      471.445496\n",
      "1960-09-01  461.0      373.449829\n",
      "1960-10-01  390.0      358.883545\n",
      "1960-11-01  432.0      317.622345\n",
      "\n",
      "[144 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "variable=lead1<br>Date=%{x}<br>Air Passengers=%{y}<extra></extra>",
         "legendgroup": "lead1",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "lead1",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "1949-01-01T00:00:00",
          "1949-02-01T00:00:00",
          "1949-03-01T00:00:00",
          "1949-04-01T00:00:00",
          "1949-05-01T00:00:00",
          "1949-06-01T00:00:00",
          "1949-07-01T00:00:00",
          "1949-08-01T00:00:00",
          "1949-09-01T00:00:00",
          "1949-10-01T00:00:00",
          "1949-11-01T00:00:00",
          "1949-12-01T00:00:00",
          "1950-01-01T00:00:00",
          "1950-02-01T00:00:00",
          "1950-03-01T00:00:00",
          "1950-04-01T00:00:00",
          "1950-05-01T00:00:00",
          "1950-06-01T00:00:00",
          "1950-07-01T00:00:00",
          "1950-08-01T00:00:00",
          "1950-09-01T00:00:00",
          "1950-10-01T00:00:00",
          "1950-11-01T00:00:00",
          "1950-12-01T00:00:00",
          "1951-01-01T00:00:00",
          "1951-02-01T00:00:00",
          "1951-03-01T00:00:00",
          "1951-04-01T00:00:00",
          "1951-05-01T00:00:00",
          "1951-06-01T00:00:00",
          "1951-07-01T00:00:00",
          "1951-08-01T00:00:00",
          "1951-09-01T00:00:00",
          "1951-10-01T00:00:00",
          "1951-11-01T00:00:00",
          "1951-12-01T00:00:00",
          "1952-01-01T00:00:00",
          "1952-02-01T00:00:00",
          "1952-03-01T00:00:00",
          "1952-04-01T00:00:00",
          "1952-05-01T00:00:00",
          "1952-06-01T00:00:00",
          "1952-07-01T00:00:00",
          "1952-08-01T00:00:00",
          "1952-09-01T00:00:00",
          "1952-10-01T00:00:00",
          "1952-11-01T00:00:00",
          "1952-12-01T00:00:00",
          "1953-01-01T00:00:00",
          "1953-02-01T00:00:00",
          "1953-03-01T00:00:00",
          "1953-04-01T00:00:00",
          "1953-05-01T00:00:00",
          "1953-06-01T00:00:00",
          "1953-07-01T00:00:00",
          "1953-08-01T00:00:00",
          "1953-09-01T00:00:00",
          "1953-10-01T00:00:00",
          "1953-11-01T00:00:00",
          "1953-12-01T00:00:00",
          "1954-01-01T00:00:00",
          "1954-02-01T00:00:00",
          "1954-03-01T00:00:00",
          "1954-04-01T00:00:00",
          "1954-05-01T00:00:00",
          "1954-06-01T00:00:00",
          "1954-07-01T00:00:00",
          "1954-08-01T00:00:00",
          "1954-09-01T00:00:00",
          "1954-10-01T00:00:00",
          "1954-11-01T00:00:00",
          "1954-12-01T00:00:00",
          "1955-01-01T00:00:00",
          "1955-02-01T00:00:00",
          "1955-03-01T00:00:00",
          "1955-04-01T00:00:00",
          "1955-05-01T00:00:00",
          "1955-06-01T00:00:00",
          "1955-07-01T00:00:00",
          "1955-08-01T00:00:00",
          "1955-09-01T00:00:00",
          "1955-10-01T00:00:00",
          "1955-11-01T00:00:00",
          "1955-12-01T00:00:00",
          "1956-01-01T00:00:00",
          "1956-02-01T00:00:00",
          "1956-03-01T00:00:00",
          "1956-04-01T00:00:00",
          "1956-05-01T00:00:00",
          "1956-06-01T00:00:00",
          "1956-07-01T00:00:00",
          "1956-08-01T00:00:00",
          "1956-09-01T00:00:00",
          "1956-10-01T00:00:00",
          "1956-11-01T00:00:00",
          "1956-12-01T00:00:00",
          "1957-01-01T00:00:00",
          "1957-02-01T00:00:00",
          "1957-03-01T00:00:00",
          "1957-04-01T00:00:00",
          "1957-05-01T00:00:00",
          "1957-06-01T00:00:00",
          "1957-07-01T00:00:00",
          "1957-08-01T00:00:00",
          "1957-09-01T00:00:00",
          "1957-10-01T00:00:00",
          "1957-11-01T00:00:00",
          "1957-12-01T00:00:00",
          "1958-01-01T00:00:00",
          "1958-01-01T00:00:00",
          "1958-02-01T00:00:00",
          "1958-03-01T00:00:00",
          "1958-04-01T00:00:00",
          "1958-05-01T00:00:00",
          "1958-06-01T00:00:00",
          "1958-07-01T00:00:00",
          "1958-08-01T00:00:00",
          "1958-09-01T00:00:00",
          "1958-10-01T00:00:00",
          "1958-11-01T00:00:00",
          "1958-12-01T00:00:00",
          "1959-01-01T00:00:00",
          "1959-02-01T00:00:00",
          "1959-03-01T00:00:00",
          "1959-04-01T00:00:00",
          "1959-05-01T00:00:00",
          "1959-06-01T00:00:00",
          "1959-07-01T00:00:00",
          "1959-08-01T00:00:00",
          "1959-09-01T00:00:00",
          "1959-10-01T00:00:00",
          "1959-11-01T00:00:00",
          "1959-12-01T00:00:00",
          "1960-01-01T00:00:00",
          "1960-02-01T00:00:00",
          "1960-03-01T00:00:00",
          "1960-04-01T00:00:00",
          "1960-05-01T00:00:00",
          "1960-06-01T00:00:00",
          "1960-07-01T00:00:00",
          "1960-08-01T00:00:00",
          "1960-09-01T00:00:00",
          "1960-10-01T00:00:00",
          "1960-11-01T00:00:00"
         ],
         "xaxis": "x",
         "y": [
          118,
          132,
          129,
          121,
          135,
          148,
          148,
          136,
          119,
          104,
          118,
          115,
          126,
          141,
          135,
          125,
          149,
          170,
          170,
          158,
          133,
          114,
          140,
          145,
          150,
          178,
          163,
          172,
          178,
          199,
          199,
          184,
          162,
          146,
          166,
          171,
          180,
          193,
          181,
          183,
          218,
          230,
          242,
          209,
          191,
          172,
          194,
          196,
          196,
          236,
          235,
          229,
          243,
          264,
          272,
          237,
          211,
          180,
          201,
          204,
          188,
          235,
          227,
          234,
          264,
          302,
          293,
          259,
          229,
          203,
          229,
          242,
          233,
          267,
          269,
          270,
          315,
          364,
          347,
          312,
          274,
          237,
          278,
          284,
          277,
          317,
          313,
          318,
          374,
          413,
          405,
          355,
          306,
          271,
          306,
          315,
          301,
          356,
          348,
          355,
          422,
          465,
          467,
          404,
          347,
          305,
          336,
          340,
          318,
          318,
          362,
          348,
          363,
          435,
          491,
          505,
          404,
          359,
          310,
          337,
          360,
          342,
          406,
          396,
          420,
          472,
          548,
          559,
          463,
          407,
          362,
          405,
          417,
          391,
          419,
          461,
          472,
          535,
          622,
          606,
          508,
          461,
          390,
          432
         ],
         "yaxis": "y"
        },
        {
         "hovertemplate": "variable=Model forecast<br>Date=%{x}<br>Air Passengers=%{y}<extra></extra>",
         "legendgroup": "Model forecast",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "Model forecast",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          "1949-01-01T00:00:00",
          "1949-02-01T00:00:00",
          "1949-03-01T00:00:00",
          "1949-04-01T00:00:00",
          "1949-05-01T00:00:00",
          "1949-06-01T00:00:00",
          "1949-07-01T00:00:00",
          "1949-08-01T00:00:00",
          "1949-09-01T00:00:00",
          "1949-10-01T00:00:00",
          "1949-11-01T00:00:00",
          "1949-12-01T00:00:00",
          "1950-01-01T00:00:00",
          "1950-02-01T00:00:00",
          "1950-03-01T00:00:00",
          "1950-04-01T00:00:00",
          "1950-05-01T00:00:00",
          "1950-06-01T00:00:00",
          "1950-07-01T00:00:00",
          "1950-08-01T00:00:00",
          "1950-09-01T00:00:00",
          "1950-10-01T00:00:00",
          "1950-11-01T00:00:00",
          "1950-12-01T00:00:00",
          "1951-01-01T00:00:00",
          "1951-02-01T00:00:00",
          "1951-03-01T00:00:00",
          "1951-04-01T00:00:00",
          "1951-05-01T00:00:00",
          "1951-06-01T00:00:00",
          "1951-07-01T00:00:00",
          "1951-08-01T00:00:00",
          "1951-09-01T00:00:00",
          "1951-10-01T00:00:00",
          "1951-11-01T00:00:00",
          "1951-12-01T00:00:00",
          "1952-01-01T00:00:00",
          "1952-02-01T00:00:00",
          "1952-03-01T00:00:00",
          "1952-04-01T00:00:00",
          "1952-05-01T00:00:00",
          "1952-06-01T00:00:00",
          "1952-07-01T00:00:00",
          "1952-08-01T00:00:00",
          "1952-09-01T00:00:00",
          "1952-10-01T00:00:00",
          "1952-11-01T00:00:00",
          "1952-12-01T00:00:00",
          "1953-01-01T00:00:00",
          "1953-02-01T00:00:00",
          "1953-03-01T00:00:00",
          "1953-04-01T00:00:00",
          "1953-05-01T00:00:00",
          "1953-06-01T00:00:00",
          "1953-07-01T00:00:00",
          "1953-08-01T00:00:00",
          "1953-09-01T00:00:00",
          "1953-10-01T00:00:00",
          "1953-11-01T00:00:00",
          "1953-12-01T00:00:00",
          "1954-01-01T00:00:00",
          "1954-02-01T00:00:00",
          "1954-03-01T00:00:00",
          "1954-04-01T00:00:00",
          "1954-05-01T00:00:00",
          "1954-06-01T00:00:00",
          "1954-07-01T00:00:00",
          "1954-08-01T00:00:00",
          "1954-09-01T00:00:00",
          "1954-10-01T00:00:00",
          "1954-11-01T00:00:00",
          "1954-12-01T00:00:00",
          "1955-01-01T00:00:00",
          "1955-02-01T00:00:00",
          "1955-03-01T00:00:00",
          "1955-04-01T00:00:00",
          "1955-05-01T00:00:00",
          "1955-06-01T00:00:00",
          "1955-07-01T00:00:00",
          "1955-08-01T00:00:00",
          "1955-09-01T00:00:00",
          "1955-10-01T00:00:00",
          "1955-11-01T00:00:00",
          "1955-12-01T00:00:00",
          "1956-01-01T00:00:00",
          "1956-02-01T00:00:00",
          "1956-03-01T00:00:00",
          "1956-04-01T00:00:00",
          "1956-05-01T00:00:00",
          "1956-06-01T00:00:00",
          "1956-07-01T00:00:00",
          "1956-08-01T00:00:00",
          "1956-09-01T00:00:00",
          "1956-10-01T00:00:00",
          "1956-11-01T00:00:00",
          "1956-12-01T00:00:00",
          "1957-01-01T00:00:00",
          "1957-02-01T00:00:00",
          "1957-03-01T00:00:00",
          "1957-04-01T00:00:00",
          "1957-05-01T00:00:00",
          "1957-06-01T00:00:00",
          "1957-07-01T00:00:00",
          "1957-08-01T00:00:00",
          "1957-09-01T00:00:00",
          "1957-10-01T00:00:00",
          "1957-11-01T00:00:00",
          "1957-12-01T00:00:00",
          "1958-01-01T00:00:00",
          "1958-01-01T00:00:00",
          "1958-02-01T00:00:00",
          "1958-03-01T00:00:00",
          "1958-04-01T00:00:00",
          "1958-05-01T00:00:00",
          "1958-06-01T00:00:00",
          "1958-07-01T00:00:00",
          "1958-08-01T00:00:00",
          "1958-09-01T00:00:00",
          "1958-10-01T00:00:00",
          "1958-11-01T00:00:00",
          "1958-12-01T00:00:00",
          "1959-01-01T00:00:00",
          "1959-02-01T00:00:00",
          "1959-03-01T00:00:00",
          "1959-04-01T00:00:00",
          "1959-05-01T00:00:00",
          "1959-06-01T00:00:00",
          "1959-07-01T00:00:00",
          "1959-08-01T00:00:00",
          "1959-09-01T00:00:00",
          "1959-10-01T00:00:00",
          "1959-11-01T00:00:00",
          "1959-12-01T00:00:00",
          "1960-01-01T00:00:00",
          "1960-02-01T00:00:00",
          "1960-03-01T00:00:00",
          "1960-04-01T00:00:00",
          "1960-05-01T00:00:00",
          "1960-06-01T00:00:00",
          "1960-07-01T00:00:00",
          "1960-08-01T00:00:00",
          "1960-09-01T00:00:00",
          "1960-10-01T00:00:00",
          "1960-11-01T00:00:00"
         ],
         "xaxis": "x",
         "y": [
          124.14868927001953,
          129.3794403076172,
          140.32972717285156,
          134.11317443847656,
          130.1815185546875,
          145.31484985351562,
          152.7608642578125,
          151.59249877929688,
          141.88320922851562,
          129.43356323242188,
          119.7403335571289,
          133.20608520507812,
          123.3521499633789,
          136.70298767089844,
          147.22824096679688,
          138.6229248046875,
          133.7951202392578,
          158.54458618164062,
          172.67349243164062,
          172.09014892578125,
          163.97702026367188,
          141.47842407226562,
          128.5456085205078,
          152.45440673828125,
          147.17552185058594,
          155.4493408203125,
          182.8551788330078,
          162.7364501953125,
          181.55224609375,
          182.6673126220703,
          203.30227661132812,
          203.25906372070312,
          194.55621337890625,
          174.93507385253906,
          157.86764526367188,
          175.22616577148438,
          173.474609375,
          185.3878631591797,
          197.6981658935547,
          186.10305786132812,
          193.7239990234375,
          219.73097229003906,
          234.18116760253906,
          258.4071350097656,
          207.02481079101562,
          207.96536254882812,
          188.26422119140625,
          202.99659729003906,
          199.4967498779297,
          205.02621459960938,
          236.9418182373047,
          242.7113494873047,
          243.72625732421875,
          263.3125915527344,
          280.6535339355469,
          267.6488952636719,
          229.7244415283203,
          208.50537109375,
          200.63966369628906,
          214.06982421875,
          208.49818420410156,
          198.48068237304688,
          235.41700744628906,
          230.89883422851562,
          254.60848999023438,
          281.9319152832031,
          311.301025390625,
          261.406494140625,
          260.5861511230469,
          227.4696044921875,
          206.66796875,
          243.33419799804688,
          253.14585876464844,
          240.6972198486328,
          285.12408447265625,
          264.97216796875,
          293.9479675292969,
          337.5972595214844,
          361.3545227050781,
          311.8260498046875,
          295.25390625,
          266.4547119140625,
          235.59201049804688,
          272.66424560546875,
          272.51983642578125,
          301.1502685546875,
          328.5368957519531,
          292.70745849609375,
          350.7896728515625,
          410.7994384765625,
          417.439453125,
          346.58837890625,
          295.3785400390625,
          268.73516845703125,
          269.1577453613281,
          305.7107849121094,
          307.78118896484375,
          325.6884765625,
          358.70556640625,
          317.9813537597656,
          399.70513916015625,
          472.74957275390625,
          428.43853759765625,
          378.3005676269531,
          326.33489990234375,
          292.44146728515625,
          280.5247802734375,
          344.8319396972656,
          356.016845703125,
          379.81536865234375,
          325.687744140625,
          380.39111328125,
          319.6492614746094,
          415.52703857421875,
          477.53204345703125,
          451.69183349609375,
          406.8389892578125,
          323.069091796875,
          312.9084777832031,
          271.245849609375,
          349.1785583496094,
          396.35894775390625,
          323.24176025390625,
          457.8265380859375,
          344.4195251464844,
          402.7438659667969,
          436.47998046875,
          484.5245666503906,
          444.03076171875,
          353.7113342285156,
          331.53857421875,
          308.23211669921875,
          464.454833984375,
          373.7249450683594,
          327.91595458984375,
          420.5564270019531,
          419.52191162109375,
          386.0882568359375,
          456.9674072265625,
          532.0049438476562,
          471.44549560546875,
          373.4498291015625,
          358.883544921875,
          317.6223449707031
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "annotations": [
         {
          "showarrow": false,
          "text": "Test set start",
          "x": 0.75,
          "xref": "paper",
          "y": 0.8,
          "yref": "paper"
         }
        ],
        "legend": {
         "orientation": "h",
         "title": {
          "text": ""
         },
         "tracegroupgap": 0,
         "y": 1.02
        },
        "margin": {
         "t": 60
        },
        "shapes": [
         {
          "line": {
           "dash": "dash",
           "width": 4
          },
          "type": "line",
          "x0": "1958-01-01",
          "x1": "1958-01-01",
          "xref": "x",
          "y0": 0,
          "y1": 1,
          "yref": "y domain"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "#C8D4E3",
             "linecolor": "#C8D4E3",
             "minorgridcolor": "#C8D4E3",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "font": {
           "size": 18
          },
          "xaxis": {
           "title": {
            "font": {
             "size": 24
            }
           }
          },
          "yaxis": {
           "title": {
            "font": {
             "size": 24
            }
           }
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Date"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Air Passengers"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Store losses per epoch\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "print(\"Untrained test\\n--------\")\n",
    "initial_test_loss = test_model(test_loader, model, loss_function)\n",
    "test_losses.append(initial_test_loss)\n",
    "print()\n",
    "\n",
    "\n",
    "for ix_epoch in range(130):\n",
    "    print(f\"Epoch {ix_epoch}\\n---------\")\n",
    "    train_loss = train_model(train_loader, model, loss_function, optimizer=optimizer)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    test_loss = test_model(test_loader, model, loss_function)\n",
    "    test_losses.append(test_loss)\n",
    "    print()\n",
    "\n",
    "print(\"Hidden SİZE XD\", model.hidden_size)\n",
    "\n",
    "# Plot loss per epoch\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Testing loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# # Evaluation\n",
    "\n",
    "# %%\n",
    "def predict(data_loader, model):\n",
    "    \"\"\"Just like `test_loop` function but keep track of the outputs instead of the loss\n",
    "    function.\n",
    "    \"\"\"\n",
    "    output = torch.tensor([])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, _ in data_loader:\n",
    "            y_star = model(X)\n",
    "            output = torch.cat((output, y_star), 0)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# %%\n",
    "train_eval_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "ystar_col = \"Model forecast\"\n",
    "df_train[ystar_col] = predict(train_eval_loader, model).numpy()\n",
    "df_test[ystar_col] = predict(test_loader, model).numpy()\n",
    "\n",
    "df_out = pd.concat((df_train, df_test))[[target, ystar_col]]\n",
    "\n",
    "for c in df_out.columns:\n",
    "    df_out[c] = df_out[c] * target_stdev + target_mean\n",
    "\n",
    "print(df_out)\n",
    "\n",
    "# %%\n",
    "fig = px.line(df_out, labels={'value': \"Air Passengers\", 'Month': 'Date'})\n",
    "fig.add_vline(x=test_start, line_width=4, line_dash=\"dash\")\n",
    "fig.add_annotation(xref=\"paper\", x=0.75, yref=\"paper\", y=0.8, text=\"Test set start\", showarrow=False)\n",
    "fig.update_layout(\n",
    "  template=plot_template, legend=dict(orientation='h', y=1.02, title_text=\"\")\n",
    ")\n",
    "fig.show()\n",
    "# fig.write_image(\"air_passengers_forecast.png\", width=1200, height=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE 0.09003753813396176\n",
      "Test MAPE 0.14455130625093202\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "mape = mean_absolute_percentage_error(df_out['Model forecast'], df_out['lead1'])\n",
    "mape_test = mean_absolute_percentage_error(df_out['lead1'].iloc[118:144], df_out['Model forecast'].iloc[118:144])\n",
    "print(\"MAPE\", mape)\n",
    "print(\"Test MAPE\", mape_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (3.11.2)",
   "language": "python",
   "name": "3.11.2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
